{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example: Time Series Model - Bouncing MNIST in NumPyro\n",
        "\n",
        "This example illustrates how to construct an inference program based on the APGS\n",
        "sampler [1] for BMNIST. The details of BMNIST can be found in the sections\n",
        "6.4 and F.3 of the reference. We will use the NumPyro (default) backend for this\n",
        "example.\n",
        "\n",
        "**References**\n",
        "\n",
        "    1. Wu, Hao, et al. Amortized population Gibbs samplers with neural\n",
        "       sufficient statistics. ICML 2020.\n",
        "\n",
        "<img src=\"file://../_static/bmnist.gif\" align=\"center\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/aleatory/aleatory-numpyro/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2024-07-29 14:21:48.770265: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-29 14:21:48.784742: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-29 14:21:48.788856: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-29 14:21:49.531813: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "from functools import partial\n",
        "\n",
        "import coix\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "from jax import random\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's load the moving mnist dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def load_dataset(*, is_training, batch_size):\n",
        "  ds = tfds.load(\"moving_mnist:1.0.0\", split=\"test\")\n",
        "  ds = ds.repeat()\n",
        "  if is_training:\n",
        "    ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "    map_fn = lambda x: x[\"image_sequence\"][..., :10, :, :, 0] / 255\n",
        "  else:\n",
        "    map_fn = lambda x: x[\"image_sequence\"][..., 0] / 255\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.map(map_fn)\n",
        "  return iter(tfds.as_numpy(ds))\n",
        "\n",
        "\n",
        "def get_digit_mean():\n",
        "  ds, ds_info = tfds.load(\"mnist:3.0.1\", split=\"train\", with_info=True)\n",
        "  ds = tfds.as_numpy(ds.batch(ds_info.splits[\"train\"].num_examples))\n",
        "  digit_mean = next(iter(ds))[\"image\"].squeeze(-1).mean(axis=0)\n",
        "  return digit_mean / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we define the neural proposals for the Gibbs kernels and the neural\n",
        "decoder for the generative model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def scale_and_translate(image, where, out_size):\n",
        "  translate = abs(image.shape[-1] - out_size) * (where[..., ::-1] + 1) / 2\n",
        "  return jax.image.scale_and_translate(\n",
        "      image,\n",
        "      (out_size, out_size),\n",
        "      (0, 1),\n",
        "      jnp.ones(2),\n",
        "      translate,\n",
        "      method=\"cubic\",\n",
        "      antialias=False,\n",
        "  )\n",
        "\n",
        "\n",
        "def crop_frames(frames, z_where, digit_size=28):\n",
        "  # frames:           time.frame_size.frame_size\n",
        "  # z_where: (digits).time.2\n",
        "  # out:     (digits).time.digit_size.digit_size\n",
        "  if frames.ndim == 2 and z_where.ndim == 1:\n",
        "    return scale_and_translate(frames, z_where, out_size=digit_size)\n",
        "  elif frames.ndim == 3 and z_where.ndim == 2:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim == 3 and z_where.ndim == 3:\n",
        "    in_axes = (None, 0)\n",
        "  elif frames.ndim == z_where.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim > z_where.ndim:\n",
        "    in_axes = (0, None)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  return jax.vmap(partial(crop_frames, digit_size=digit_size), in_axes)(\n",
        "      frames, z_where\n",
        "  )\n",
        "\n",
        "\n",
        "def embed_digits(digits, z_where, frame_size=64):\n",
        "  # digits:  (digits).      .digit_size.digit_size\n",
        "  # z_where: (digits).(time).2\n",
        "  # out:     (digits).(time).frame_size.frame_size\n",
        "  if digits.ndim == 2 and z_where.ndim == 1:\n",
        "    return scale_and_translate(digits, z_where, out_size=frame_size)\n",
        "  elif digits.ndim == 2 and z_where.ndim == 2:\n",
        "    in_axes = (None, 0)\n",
        "  elif digits.ndim >= z_where.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  return jax.vmap(partial(embed_digits, frame_size=frame_size), in_axes)(\n",
        "      digits, z_where\n",
        "  )\n",
        "\n",
        "\n",
        "def conv2d(frames, digits):\n",
        "  # frames:          (time).frame_size.frame_size\n",
        "  # digits: (digits).      .digit_size.digit_size\n",
        "  # out:    (digits).(time).conv_size .conv_size\n",
        "  if frames.ndim == 2 and digits.ndim == 2:\n",
        "    return jax.scipy.signal.convolve2d(frames, digits, mode=\"valid\")\n",
        "  elif frames.ndim == digits.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim > digits.ndim:\n",
        "    in_axes = (0, None)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  return jax.vmap(conv2d, in_axes=in_axes)(frames, digits)\n",
        "\n",
        "\n",
        "class EncoderWhat(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, digits):\n",
        "    x = digits.reshape(digits.shape[:-2] + (-1,))\n",
        "    x = nn.Dense(400)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = nn.relu(x)\n",
        "\n",
        "    x = x.sum(-2)  # sum/mean across time\n",
        "    loc_raw = nn.Dense(10)(x)\n",
        "    scale_raw = 0.5 * nn.Dense(10)(x)\n",
        "    return loc_raw, jnp.exp(scale_raw)\n",
        "\n",
        "\n",
        "class EncoderWhere(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, frame_conv):\n",
        "    x = frame_conv.reshape(frame_conv.shape[:-2] + (-1,))\n",
        "    x = nn.softmax(x, -1)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = x.reshape(x.shape[:-1] + (2, 100))\n",
        "    x = nn.relu(x)\n",
        "    loc_raw = nn.Dense(2)(x[..., 0, :])\n",
        "    scale_raw = 0.5 * nn.Dense(2)(x[..., 1, :])\n",
        "    return nn.tanh(loc_raw), jnp.exp(scale_raw)\n",
        "\n",
        "\n",
        "class DecoderWhat(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, z_what):\n",
        "    x = nn.Dense(200)(z_what)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(400)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(784)(x)\n",
        "    logits = x.reshape(x.shape[:-1] + (28, 28))\n",
        "    return nn.sigmoid(logits)\n",
        "\n",
        "\n",
        "class BMNISTAutoEncoder(nn.Module):\n",
        "  digit_mean: jnp.ndarray\n",
        "  frame_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.encode_what = EncoderWhat()\n",
        "    self.encode_where = EncoderWhere()\n",
        "    self.decode_what = DecoderWhat()\n",
        "\n",
        "  def __call__(self, frames):\n",
        "    # Heuristic procedure to setup initial parameters.\n",
        "    frames_conv = conv2d(frames, self.digit_mean)\n",
        "    z_where, _ = self.encode_where(frames_conv)\n",
        "\n",
        "    digits = crop_frames(frames, z_where, 28)\n",
        "    print(digits.shape)\n",
        "    z_what, _ = self.encode_what(digits)\n",
        "\n",
        "    print(z_what.shape)\n",
        "    digit_recon = self.decode_what(z_what)\n",
        "    print(digit_recon.shape)\n",
        "    frames_recon = embed_digits(digit_recon, z_where, self.frame_size)\n",
        "    return frames_recon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the target and kernels as in Section 6.4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def bmnist_target(network, inputs, D=2, T=10):\n",
        "  z_what = numpyro.sample(\n",
        "      \"z_what\", dist.Normal(0, 1).expand([D, 10]).to_event()\n",
        "  )\n",
        "  digits = network.decode_what(z_what)  # can cache this\n",
        "\n",
        "  z_where = []\n",
        "  # p = []\n",
        "  for d in range(D):\n",
        "    z_where_d = []\n",
        "    z_where_d_t = jnp.zeros(2)\n",
        "    for t in range(T):\n",
        "      scale = 1 if t == 0 else 0.1\n",
        "      z_where_d_t = numpyro.sample(\n",
        "          f\"z_where_{d}_{t}\", dist.Normal(z_where_d_t, scale).to_event(1)\n",
        "      )\n",
        "      z_where_d.append(z_where_d_t)\n",
        "    z_where_d = jnp.stack(z_where_d, -2)\n",
        "    z_where.append(z_where_d)\n",
        "  z_where = jnp.stack(z_where, -3)\n",
        "\n",
        "  p = embed_digits(digits, z_where, network.frame_size)\n",
        "  p = dist.util.clamp_probs(p.sum(-4))  # sum across digits\n",
        "  frames = numpyro.sample(\"frames\", dist.Bernoulli(p).to_event(3), obs=inputs)\n",
        "\n",
        "  out = {\n",
        "      \"frames\": frames,\n",
        "      \"frames_recon\": p,\n",
        "      \"z_what\": z_what,\n",
        "      \"digits\": jax.lax.stop_gradient(digits),\n",
        "      **{f\"z_where_{t}\": z_where[..., t, :] for t in range(T)},\n",
        "  }\n",
        "  return (out,)\n",
        "\n",
        "\n",
        "def kernel_where(network, inputs, D=2, t=0):\n",
        "  if not isinstance(inputs, dict):\n",
        "    inputs = {\n",
        "        \"frames\": inputs,\n",
        "        \"digits\": jnp.repeat(jnp.expand_dims(network.digit_mean, -3), D, -3),\n",
        "    }\n",
        "\n",
        "  frame = inputs[\"frames\"][..., t, :, :]\n",
        "  z_where_t = []\n",
        "  for d in range(D):\n",
        "    digit = inputs[\"digits\"][..., d, :, :]\n",
        "    x_conv = conv2d(frame, digit)\n",
        "    loc, scale = network.encode_where(x_conv)\n",
        "    z_where_d_t = numpyro.sample(\n",
        "        f\"z_where_{d}_{t}\", dist.Normal(loc, scale).to_event(1)\n",
        "    )\n",
        "    z_where_t.append(z_where_d_t)\n",
        "    frame_recon = embed_digits(digit, z_where_d_t, network.frame_size)\n",
        "    frame = frame - frame_recon\n",
        "  z_where_t = jnp.stack(z_where_t, -2)\n",
        "\n",
        "  out = {**inputs, **{f\"z_where_{t}\": z_where_t}}\n",
        "  return (out,)\n",
        "\n",
        "\n",
        "def kernel_what(network, inputs, T=10):\n",
        "  z_where = jnp.stack([inputs[f\"z_where_{t}\"] for t in range(T)], -2)\n",
        "  digits = crop_frames(inputs[\"frames\"], z_where, 28)\n",
        "  loc, scale = network.encode_what(digits)\n",
        "  z_what = numpyro.sample(\"z_what\", dist.Normal(loc, scale).to_event(2))\n",
        "\n",
        "  out = {**inputs, **{\"z_what\": z_what}}\n",
        "  return (out,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we create the bmnist inference program, define the loss function,\n",
        "run the training loop, and plot the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def make_bmnist(params, bmnist_net, T=10, num_sweeps=5, num_particles=10):\n",
        "  network = coix.util.BindModule(bmnist_net, params)\n",
        "  # Add particle dimension and construct a program.\n",
        "  make_particle_plate = lambda: numpyro.plate(\"particle\", num_particles, dim=-2)\n",
        "  target = make_particle_plate()(partial(bmnist_target, network, D=2, T=T))\n",
        "  kernels = []\n",
        "  for t in range(T):\n",
        "    kernels.append(\n",
        "        make_particle_plate()(partial(kernel_where, network, D=2, t=t))\n",
        "    )\n",
        "  kernels.append(make_particle_plate()(partial(kernel_what, network, T=T)))\n",
        "  program = coix.algo.apgs(target, kernels, num_sweeps=num_sweeps)\n",
        "  return program\n",
        "\n",
        "\n",
        "def loss_fn(params, key, batch, bmnist_net, num_sweeps, num_particles):\n",
        "  # Prepare data for the program.\n",
        "  shuffle_rng, rng_key = random.split(key)\n",
        "  batch = random.permutation(shuffle_rng, batch, axis=1)\n",
        "  T = batch.shape[-3]\n",
        "\n",
        "  # Run the program and get metrics.\n",
        "  program = make_bmnist(params, bmnist_net, T, num_sweeps, num_particles)\n",
        "  _, _, metrics = coix.traced_evaluate(program, seed=rng_key)(batch)\n",
        "  for metric_name in [\"log_Z\", \"log_density\", \"loss\"]:\n",
        "    metrics[metric_name] = metrics[metric_name] / batch.shape[0]\n",
        "  return metrics[\"loss\"], metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Args(argparse.Namespace):\n",
        "  # batch_size = 5\n",
        "  batch_size = 3\n",
        "  num_sweeps = 5\n",
        "  num_particles = 10\n",
        "  learning_rate = 1e-4\n",
        "  num_steps = 20000\n",
        "  device = \"gpu\"\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You use TensorFlow DType <dtype: 'uint8'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint8.\n",
            "2024-07-29 14:21:55.943059: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
            "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
            "WARNING:jax._src.xla_bridge:An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20, 28, 28)\n",
            "(28, 28)\n"
          ]
        }
      ],
      "source": [
        "lr = args.learning_rate\n",
        "num_steps = args.num_steps\n",
        "batch_size = args.batch_size\n",
        "num_sweeps = args.num_sweeps\n",
        "num_particles = args.num_particles\n",
        "train_ds = load_dataset(is_training=True, batch_size=batch_size)\n",
        "test_ds = load_dataset(is_training=False, batch_size=1)\n",
        "digit_mean = get_digit_mean()\n",
        "test_data = next(test_ds)\n",
        "frame_size = test_data.shape[-1]\n",
        "bmnist_net = BMNISTAutoEncoder(digit_mean=digit_mean, frame_size=frame_size)\n",
        "init_params = bmnist_net.init(jax.random.PRNGKey(0), test_data[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bmnist_params, _ = coix.util.train(\n",
        "    partial(\n",
        "        loss_fn,\n",
        "        bmnist_net=bmnist_net,\n",
        "        num_sweeps=num_sweeps,\n",
        "        num_particles=num_particles,\n",
        "    ),\n",
        "    init_params,\n",
        "    optax.adam(lr),\n",
        "    num_steps,\n",
        "    train_ds,\n",
        ")\n",
        "T_test = test_data.shape[-3]\n",
        "program = make_bmnist(\n",
        "    bmnist_params, bmnist_net, T_test, num_sweeps, num_particles\n",
        ")\n",
        "out, _, _ = coix.traced_evaluate(program, seed=jax.random.PRNGKey(1))(\n",
        "    test_data\n",
        ")\n",
        "out = out[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "  prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
        "  colors = prop_cycle.by_key()[\"color\"]\n",
        "  fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "  def animate(i):\n",
        "    axes[0].cla()\n",
        "    axes[0].imshow(test_data[0, i])\n",
        "    axes[1].cla()\n",
        "    axes[1].imshow(out[\"frames_recon\"][0, 0, i])\n",
        "    for d in range(2):\n",
        "      where = 0.5 * (out[f\"z_where_{i}\"][0, 0, d] + 1) * (frame_size - 28) - 0.5\n",
        "      color = colors[d]\n",
        "      axes[0].add_patch(\n",
        "          Rectangle(where, 28, 28, edgecolor=color, lw=3, fill=False)\n",
        "      )\n",
        "\n",
        "  plt.rc(\"animation\", html=\"jshtml\")\n",
        "  plt.tight_layout()\n",
        "  ani = animation.FuncAnimation(fig, animate, frames=range(20), interval=300)\n",
        "  writer = animation.PillowWriter(fps=15)\n",
        "  ani.save(\"bmnist.gif\", writer=writer)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  parser = argparse.ArgumentParser(description=\"Annealing example\")\n",
        "  parser.add_argument(\"--batch-size\", nargs=\"?\", default=5, type=int)\n",
        "  parser.add_argument(\"--num-sweeps\", nargs=\"?\", default=5, type=int)\n",
        "  parser.add_argument(\"--num_particles\", nargs=\"?\", default=10, type=int)\n",
        "  parser.add_argument(\"--learning-rate\", nargs=\"?\", default=1e-4, type=float)\n",
        "  parser.add_argument(\"--num-steps\", nargs=\"?\", default=20000, type=int)\n",
        "  parser.add_argument(\n",
        "      \"--device\", default=\"gpu\", type=str, help='use \"cpu\" or \"gpu\".'\n",
        "  )\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  tf.config.experimental.set_visible_devices([], \"GPU\")  # Disable GPU for TF.\n",
        "  numpyro.set_platform(args.device)\n",
        "\n",
        "  main(args)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
