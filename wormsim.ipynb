{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example: Time Series Model - Bouncing MNIST in NumPyro\n",
        "\n",
        "This example illustrates how to construct an inference program based on the APGS\n",
        "sampler [1] for BMNIST. The details of BMNIST can be found in the sections\n",
        "6.4 and F.3 of the reference. We will use the NumPyro (default) backend for this\n",
        "example.\n",
        "\n",
        "**References**\n",
        "\n",
        "    1. Wu, Hao, et al. Amortized population Gibbs samplers with neural\n",
        "       sufficient statistics. ICML 2020.\n",
        "\n",
        "<img src=\"file://../_static/bmnist.gif\" align=\"center\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/frans/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2024-08-03 17:22:40.044721: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-03 17:22:40.054860: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-03 17:22:40.057699: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-03 17:22:40.573524: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "from functools import partial\n",
        "\n",
        "import coix\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "from jax import random\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "import optax\n",
        "from optax import cosine_decay_schedule\n",
        "from optax import clip_by_global_norm\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sim_utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's load the moving mnist dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# def load_dataset(*, is_training, batch_size):\n",
        "#   ds = tfds.load(\"moving_mnist:1.0.0\", split=\"test\")\n",
        "#   ds = ds.repeat()\n",
        "#   if is_training:\n",
        "#     ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "#     map_fn = lambda x: x[\"image_sequence\"][..., :10, :, :, 0] / 255\n",
        "#   else:\n",
        "#     map_fn = lambda x: x[\"image_sequence\"][..., 0] / 255\n",
        "#   ds = ds.batch(batch_size)\n",
        "#   ds = ds.map(map_fn)\n",
        "#   return iter(tfds.as_numpy(ds))\n",
        "\n",
        "def load_dataset(*, is_training, batch_size, n_data = -1):\n",
        "  # ds = np.load(\"worms_train_20k.npy\")\n",
        "  ds = np.load(\"worms_train.npy\")\n",
        "  ds = ds[:n_data]\n",
        "\n",
        "  # make ds a tensor, and batch it\n",
        "  ds = tf.data.Dataset.from_tensor_slices(ds)\n",
        "  ds = ds.repeat()\n",
        "  if is_training:\n",
        "    ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "  ds = ds.batch(batch_size)\n",
        "  # standardize the data between 0 and 1\n",
        "  ds = ds.map(lambda x: x / 0.80999994)\n",
        "  return iter(tfds.as_numpy(ds))\n",
        "\n",
        "def get_digit_mean():\n",
        "  ds, ds_info = tfds.load(\"mnist:3.0.1\", split=\"train\", with_info=True)\n",
        "  ds = tfds.as_numpy(ds.batch(ds_info.splits[\"train\"].num_examples))\n",
        "  digit_mean = next(iter(ds))[\"image\"].squeeze(-1).mean(axis=0)\n",
        "  return digit_mean / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_digit_mean():\n",
        "  ds, ds_info = tfds.load(\"mnist:3.0.1\", split=\"train\", with_info=True)\n",
        "  ds = tfds.as_numpy(ds.batch(ds_info.splits[\"train\"].num_examples))\n",
        "  digit_mean = next(iter(ds))[\"image\"].squeeze(-1).mean(axis=0)\n",
        "  return digit_mean / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we define the neural proposals for the Gibbs kernels and the neural\n",
        "decoder for the generative model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vmapped_sim_fn(sim_fn, params):\n",
        "    # print(jax.tree_map(lambda x: x.shape if hasattr(x, 'shape') else None, params))\n",
        "    if params['L'].ndim == 1:\n",
        "        return jax.vmap(sim_fn, in_axes=0, out_axes=0)(params)\n",
        "    else:\n",
        "        return jax.vmap(partial(vmapped_sim_fn, sim_fn), in_axes=0, out_axes=0)(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sim_worms(nworms, batch_size, n_frames):\n",
        "    duration = 0.55\n",
        "    snapshots = 10\n",
        "    kpoints = 6\n",
        "    box_size = 64\n",
        "    with numpyro.plate('batch', batch_size, dim=-2):\n",
        "        with numpyro.plate('nworms', nworms, dim=-1):\n",
        "            # L = numpyro.sample('L', dist.Uniform(30, 45))\n",
        "            L = numpyro.sample('L', dist.Uniform(10, 15))\n",
        "            A = numpyro.sample('A', dist.Normal(1, 0.1))\n",
        "            T = numpyro.sample('T', dist.Normal(0.8, 0.1))\n",
        "            kw = numpyro.sample('kw', dist.Uniform(0, 2 * jnp.pi))\n",
        "            ku = numpyro.sample('ku', dist.Normal(jnp.pi, 1))\n",
        "            \n",
        "            inc = numpyro.sample('inc', dist.Uniform(0, 2 * jnp.pi))\n",
        "            dr = numpyro.sample('dr', dist.Uniform(0.2, 0.8))\n",
        "            phase_1 = numpyro.sample('phase_1', dist.Uniform(0, 2 * jnp.pi))\n",
        "            phase_2 = numpyro.sample('phase_2', dist.Uniform(0, 2 * jnp.pi))\n",
        "            phase_3 = numpyro.sample('phase_3', dist.Normal(0, 0.1))\n",
        "            alpha = numpyro.sample('alpha', dist.Normal(4, 4))\n",
        "\n",
        "            alpha = jnp.abs(alpha + 1.0)\n",
        "            half_box = box_size // 2\n",
        "            x0 = numpyro.sample('x0', dist.Uniform(-1, 1))\n",
        "            y0 = numpyro.sample('y0', dist.Uniform(-1, 1))\n",
        "            x0 = x0 * half_box\n",
        "            y0 = y0 * half_box\n",
        "\n",
        "            params = {'L': L, 'A': A, 'T': T, 'kw': kw, 'ku': ku, 'inc': inc, 'dr': dr, 'phase_1': phase_1, 'phase_2': phase_2, 'phase_3': phase_3, 'alpha': alpha, 'x0': x0, 'y0': y0}\n",
        "\n",
        "            # # L is a tensor. Assert that all values are within the range\n",
        "            # assert jnp.all(L >= 10) and jnp.all(L <= 15), f\"L: {L}\"\n",
        "            # # kw\n",
        "            # assert jnp.all(kw >= 0) and jnp.all(kw <= 2 * jnp.pi), f\"kw: {kw}\"\n",
        "            # # inc\n",
        "            # assert jnp.all(inc >= 0) and jnp.all(inc <= 2 * jnp.pi), f\"inc: {inc}\"\n",
        "            # # dr\n",
        "            # assert jnp.all(dr >= 0.2) and jnp.all(dr <= 0.8), f\"dr: {dr}\"\n",
        "            # # phase_1\n",
        "            # assert jnp.all(phase_1 >= 0) and jnp.all(phase_1 <= 2 * jnp.pi), f\"phase_1: {phase_1}\"\n",
        "            # # phase_2\n",
        "            # assert jnp.all(phase_2 >= 0) and jnp.all(phase_2 <= 2 * jnp.pi), f\"phase_2: {phase_2}\"\n",
        "            # # x0\n",
        "            # assert jnp.all(x0 >= -1) and jnp.all(x0 <= 1), f\"x0: {x0}\"\n",
        "            # # y0\n",
        "            # assert jnp.all(y0 >= -1) and jnp.all(y0 <= 1), f\"y0: {y0}\"\n",
        "\n",
        "            sim_fn = partial(\n",
        "                worm_simulation,\n",
        "                duration=duration,\n",
        "                snapshots=snapshots,\n",
        "                kpoints=kpoints,\n",
        "            )\n",
        "\n",
        "            with numpyro.plate('n_frames', n_frames):\n",
        "                worms = vmapped_sim_fn(sim_fn, params)\n",
        "                \n",
        "                worms = worms + half_box\n",
        "                # subtract mean and divide by standard deviation\n",
        "                worms = (worms - jnp.mean(worms, axis=(-5), keepdims=True)) / jnp.std(worms, axis=(-5), keepdims=True)\n",
        "                numpyro.deterministic('worms', worms)\n",
        "    return worms, x0, y0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def scale_and_translate(image, where, out_size):\n",
        "  translate = abs(image.shape[-1] - out_size) * (where[..., ::-1] + 1) / 2\n",
        "  return jax.image.scale_and_translate(\n",
        "      image,\n",
        "      (out_size, out_size),\n",
        "      (0, 1),\n",
        "      jnp.ones(2),\n",
        "      translate,\n",
        "      method=\"cubic\",\n",
        "      antialias=False,\n",
        "  )\n",
        "\n",
        "\n",
        "def crop_frames(frames, z_where, digit_size=14):\n",
        "  # frames:           time.frame_size.frame_size\n",
        "  # z_where: (digits).time.2\n",
        "  # out:     (digits).time.digit_size.digit_size\n",
        "  if frames.ndim == 2 and z_where.ndim == 1:\n",
        "    return scale_and_translate(frames, z_where, out_size=digit_size)\n",
        "  elif frames.ndim == 3 and z_where.ndim == 2:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim == 3 and z_where.ndim == 3:\n",
        "    in_axes = (None, 0)\n",
        "  elif frames.ndim == z_where.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim > z_where.ndim:\n",
        "    in_axes = (0, None)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  return jax.vmap(partial(crop_frames, digit_size=digit_size), in_axes)(\n",
        "      frames, z_where\n",
        "  )\n",
        "\n",
        "\n",
        "def embed_digits(digits, z_where, frame_size=64):\n",
        "  # digits:  (digits).      .digit_size.digit_size\n",
        "  # z_where: (digits).(time).2\n",
        "  # out:     (digits).(time).frame_size.frame_size\n",
        "  if digits.ndim == 2 and z_where.ndim == 1:\n",
        "    return scale_and_translate(digits, z_where, out_size=frame_size)\n",
        "  elif digits.ndim == 2 and z_where.ndim == 2:\n",
        "    in_axes = (None, 0)\n",
        "  elif digits.ndim >= z_where.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  # print(\"in_axes\", in_axes)\n",
        "  # print(digits.shape)\n",
        "  # print(z_where.shape)\n",
        "  return jax.vmap(partial(embed_digits, frame_size=frame_size), in_axes)(\n",
        "      digits, z_where\n",
        "  )\n",
        "\n",
        "  \n",
        "\n",
        "def conv2d(frames, digits):\n",
        "  # frames:          (time).frame_size.frame_size\n",
        "  # digits: (digits).      .digit_size.digit_size\n",
        "  # out:    (digits).(time).conv_size .conv_size\n",
        "  if frames.ndim == 2 and digits.ndim == 2:\n",
        "    return jax.scipy.signal.convolve2d(frames, digits, mode=\"valid\")\n",
        "  elif frames.ndim == digits.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim > digits.ndim:\n",
        "    in_axes = (0, None)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  return jax.vmap(conv2d, in_axes=in_axes)(frames, digits)\n",
        "\n",
        "\n",
        "# class EncoderWhat(nn.Module):\n",
        "\n",
        "#   @nn.compact\n",
        "#   def __call__(self, digits):\n",
        "#     x = digits.reshape(digits.shape[:-2] + (-1,)) # flatten frame into vector\n",
        "#     x = nn.Dense(400)(x)\n",
        "#     x = nn.relu(x)\n",
        "#     x = nn.Dense(200)(x)\n",
        "#     x = nn.relu(x)\n",
        "\n",
        "#     x = x.sum(-2)  # sum/mean across time\n",
        "#     loc_raw = nn.Dense(10)(x)\n",
        "#     scale_raw = 0.5 * nn.Dense(10)(x)\n",
        "#     return loc_raw, jnp.exp(scale_raw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EncoderWhat(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, digits, carry=None):\n",
        "    mappable_dims = digits.shape[:-3]\n",
        "    \n",
        "    hidden_dim = 128\n",
        "\n",
        "    x = digits.reshape(digits.shape[:-2] + (-1,)) # flatten frame into vector\n",
        "    if carry is None:\n",
        "      carry = self.param('carry_init', \n",
        "                         lambda rng, shape: jnp.zeros(shape), \n",
        "                         mappable_dims + (hidden_dim,))\n",
        "    GRU = nn.scan(nn.GRUCell,\n",
        "                  in_axes=-1,\n",
        "                  variable_broadcast='params',\n",
        "                  split_rngs={'params': False}\n",
        "                  )(hidden_dim)\n",
        "    # print(carry.shape)\n",
        "    # print(x.shape)\n",
        "    # add layernorm\n",
        "    \n",
        "    x = nn.LayerNorm()(x)\n",
        "    x,_ = GRU(carry, x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(64)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.LayerNorm()(x)\n",
        "    \n",
        "    x_L = nn.Dense(10)(x)\n",
        "    x_L = nn.relu(x_L)\n",
        "    x_L_loc = nn.Dense(1)(x_L)\n",
        "    # scale to 10-15\n",
        "    x_L_loc = nn.tanh(x_L_loc) * 2.5 + 12.5\n",
        "    x_L_scale = 0.5 * nn.Dense(1)(x_L)\n",
        "\n",
        "    x_A = nn.Dense(10)(x)\n",
        "    x_A = nn.relu(x_A)\n",
        "    x_A_loc = nn.Dense(1)(x_A)\n",
        "    x_A_scale = 0.5 * nn.Dense(1)(x_A)\n",
        "\n",
        "    x_T = nn.Dense(10)(x)\n",
        "    x_T = nn.relu(x_T)\n",
        "    x_T_loc = nn.Dense(1)(x_T)\n",
        "    # constrain to positive\n",
        "    x_T_loc = nn.softplus(x_T_loc)\n",
        "    x_T_scale = 0.5 * nn.Dense(1)(x_T)\n",
        "\n",
        "    x_kw = nn.Dense(10)(x)\n",
        "    x_kw = nn.relu(x_kw)\n",
        "    x_kw_loc = nn.Dense(1)(x_kw)\n",
        "    # scale to 0-2pi\n",
        "    x_kw_loc = nn.tanh(x_kw_loc) * jnp.pi + jnp.pi\n",
        "    x_kw_scale = 0.5 * nn.Dense(1)(x_kw)\n",
        "\n",
        "    x_ku = nn.Dense(10)(x)\n",
        "    x_ku = nn.relu(x_ku)\n",
        "    x_ku_loc = nn.Dense(1)(x_ku)\n",
        "    x_ku_scale = 0.5 * nn.Dense(1)(x_ku)\n",
        "\n",
        "    x_inc = nn.Dense(10)(x)\n",
        "    x_inc = nn.relu(x_inc)\n",
        "    x_inc_loc = nn.Dense(1)(x_inc)\n",
        "    # scale to 0-2pi\n",
        "    x_inc_loc = nn.tanh(x_inc_loc) * jnp.pi + jnp.pi\n",
        "    x_inc_scale = 0.5 * nn.Dense(1)(x_inc)\n",
        "\n",
        "    x_dr = nn.Dense(10)(x)\n",
        "    x_dr = nn.relu(x_dr)\n",
        "    x_dr_loc = nn.Dense(1)(x_dr)\n",
        "    # scale to 0.2-0.8\n",
        "    x_dr_loc = nn.tanh(x_dr_loc) * 0.3 + 0.5\n",
        "    x_dr_scale = 0.5 * nn.Dense(1)(x_dr)\n",
        "\n",
        "    x_phase_1 = nn.Dense(10)(x)\n",
        "    x_phase_1 = nn.relu(x_phase_1)\n",
        "    x_phase_1_loc = nn.Dense(1)(x_phase_1)\n",
        "    # scale to 0-2pi\n",
        "    x_phase_1_loc = nn.tanh(x_phase_1_loc) * jnp.pi + jnp.pi\n",
        "    x_phase_1_scale = 0.5 * nn.Dense(1)(x_phase_1)\n",
        "\n",
        "    x_phase_2 = nn.Dense(10)(x)\n",
        "    x_phase_2 = nn.relu(x_phase_2)\n",
        "    x_phase_2_loc = nn.Dense(1)(x_phase_2)\n",
        "    # scale to 0-2pi\n",
        "    x_phase_2_loc = nn.tanh(x_phase_2_loc) * jnp.pi + jnp.pi\n",
        "    x_phase_2_scale = 0.5 * nn.Dense(1)(x_phase_2)\n",
        "\n",
        "    x_phase_3 = nn.Dense(10)(x)\n",
        "    x_phase_3 = nn.relu(x_phase_3)\n",
        "    x_phase_3_loc = nn.Dense(1)(x_phase_3)\n",
        "    x_phase_3_scale = 0.5 * nn.Dense(1)(x_phase_3)\n",
        "\n",
        "    x_alpha = nn.Dense(10)(x)\n",
        "    x_alpha = nn.relu(x_alpha)\n",
        "    x_alpha_loc = nn.Dense(1)(x_alpha)\n",
        "    x_alpha_scale = 0.5 * nn.Dense(1)(x_alpha)\n",
        "\n",
        "    x_x0_loc = nn.Dense(1)(x)\n",
        "    x_x0_loc = nn.tanh(x_x0_loc) * 1\n",
        "    x_x0_scale = 0.5 * nn.Dense(1)(x)\n",
        "\n",
        "    x_y0_loc = nn.Dense(1)(x)\n",
        "    x_y0_loc = nn.tanh(x_y0_loc) * 1\n",
        "    x_y0_scale = 0.5 * nn.Dense(1)(x)\n",
        "\n",
        "    # return x_L_loc, jnp.exp(x_L_scale), x_A_loc, jnp.exp(x_A_scale), x_T_loc, jnp.exp(x_T_scale), x_kw_loc, jnp.exp(x_kw_scale), x_ku_loc, jnp.exp(x_ku_scale), x_inc_loc, jnp.exp(x_inc_scale), x_dr_loc, jnp.exp(x_dr_scale), x_phase_1_loc, jnp.exp(x_phase_1_scale), x_phase_2_loc, jnp.exp(x_phase_2_scale), x_phase_3_loc, jnp.exp(x_phase_3_scale), x_alpha_loc, jnp.exp(x_alpha_scale)\n",
        "    return x_L_loc.squeeze(-1), jnp.exp(x_L_scale.squeeze(-1)), x_A_loc.squeeze(-1), jnp.exp(x_A_scale.squeeze(-1)), x_T_loc.squeeze(-1), jnp.exp(x_T_scale.squeeze(-1)), x_kw_loc.squeeze(-1), jnp.exp(x_kw_scale.squeeze(-1)), x_ku_loc.squeeze(-1), jnp.exp(x_ku_scale.squeeze(-1)), x_inc_loc.squeeze(-1), jnp.exp(x_inc_scale.squeeze(-1)), x_dr_loc.squeeze(-1), jnp.exp(x_dr_scale.squeeze(-1)), x_phase_1_loc.squeeze(-1), jnp.exp(x_phase_1_scale.squeeze(-1)), x_phase_2_loc.squeeze(-1), jnp.exp(x_phase_2_scale.squeeze(-1)), x_phase_3_loc.squeeze(-1), jnp.exp(x_phase_3_scale.squeeze(-1)), x_alpha_loc.squeeze(-1), jnp.exp(x_alpha_scale.squeeze(-1)), x_x0_loc.squeeze(-1), jnp.exp(x_x0_scale.squeeze(-1)), x_y0_loc.squeeze(-1), jnp.exp(x_y0_scale.squeeze(-1))\n",
        "\n",
        "\n",
        "\n",
        "# class EncoderWhere(nn.Module):\n",
        "\n",
        "#   @nn.compact\n",
        "#   def __call__(self, frame_conv):\n",
        "#     x = frame_conv.reshape(frame_conv.shape[:-2] + (-1,))\n",
        "#     x = nn.softmax(x, -1)\n",
        "#     x = nn.Dense(200)(x)\n",
        "#     x = nn.relu(x)\n",
        "#     x = nn.Dense(200)(x)\n",
        "#     x = x.reshape(x.shape[:-1] + (2, 100))\n",
        "#     x = nn.relu(x)\n",
        "#     loc_raw = nn.Dense(2)(x[..., 0, :])\n",
        "#     scale_raw = 0.5 * nn.Dense(2)(x[..., 1, :])\n",
        "#     return nn.tanh(loc_raw), jnp.exp(scale_raw)\n",
        "\n",
        "class EncoderWhere(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, frame_conv):\n",
        "    x = frame_conv.reshape(frame_conv.shape[:-2] + (-1,))\n",
        "    # # concatenate worm_means to x\n",
        "    # if worm_means is None:\n",
        "    #   worm_means = jnp.zeros(x.shape[:-1] + (2,))\n",
        "    # x = jnp.concatenate([x, jnp.zeros(x.shape[:-1] + (1,))], axis=-1)\n",
        "    x = nn.softmax(x, -1)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = x.reshape(x.shape[:-1] + (2, 100))\n",
        "    x = nn.relu(x)\n",
        "    loc_raw = nn.Dense(2)(x[..., 0, :])\n",
        "    scale_raw = 0.5 * nn.Dense(2)(x[..., 1, :])\n",
        "    # return nn.tanh(loc_raw), jnp.exp(scale_raw)\n",
        "    return nn.tanh(loc_raw), nn.sigmoid(scale_raw)\n",
        "\n",
        "\n",
        "class DecoderWhat(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, z_what):\n",
        "    # print(\"z_what.shape DecoderWhat\", z_what.shape)\n",
        "    x = z_what.reshape(z_what.shape[:-2] + (-1,)) # flatten knots x 2 into vector\n",
        "    # print(\"x.shape DecoderWhat\", x.shape)\n",
        "    x = nn.Dense(50)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(100)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(196)(x)\n",
        "    logits = x.reshape(x.shape[:-1] + (14, 14))\n",
        "    return nn.sigmoid(logits)\n",
        "\n",
        "\n",
        "class BMNISTAutoEncoder(nn.Module):\n",
        "  digit_mean: jnp.ndarray\n",
        "  frame_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.encode_what = EncoderWhat()\n",
        "    self.encode_where = EncoderWhere()\n",
        "    self.decode_what = DecoderWhat()\n",
        "\n",
        "  def __call__(self, frames):\n",
        "    num_particles, batch_size, T, frame_size, frame_size = frames.shape\n",
        "    # Heuristic procedure to setup initial parameters.\n",
        "\n",
        "    z_where = []\n",
        "    for t in range(10):\n",
        "      frame = frames[..., t, :, :]\n",
        "      z_where_d = []\n",
        "      for d in range(2):\n",
        "        frames_conv = conv2d(frame, self.digit_mean)\n",
        "        # if t == 0:\n",
        "        #   plt.figure()\n",
        "        #   plt.imshow(frame[0,0])\n",
        "        #   plt.figure()\n",
        "        #   plt.imshow(self.digit_mean)\n",
        "        #   plt.figure()\n",
        "        #   plt.imshow(frames_conv[0,0])\n",
        "        z_where_t_d, _ = self.encode_where(frames_conv)\n",
        "        z_where_d.append(z_where_t_d)\n",
        "      z_where_d = jnp.stack(z_where_d, -2)\n",
        "      z_where.append(z_where_d)\n",
        "    # z_where = jnp.stack(z_where, -3).transpose(0, 2, 1, 3)\n",
        "    z_where = jnp.stack(z_where, -3).transpose(0, 1, 3, 2, 4)\n",
        "    # print(z_where.shape)\n",
        "    print(\"z_where.shape\", z_where.shape)\n",
        "    digits = crop_frames(frames, z_where, 14)\n",
        "    # print(digits.shape)\n",
        "    print(\"digits.shape\", digits.shape)\n",
        "    # z_what, _ = self.encode_what(digits)\n",
        "    proposed_sim_params = self.encode_what(digits)\n",
        "    print(proposed_sim_params[0].shape)\n",
        "    # proposed_sim_params = jax.tree_map(lambda x: x.squeeze(-1), proposed_sim_params)\n",
        "    # x0, y0 = z_where[..., 0, 0].squeeze(), z_where[..., 0, 1].squeeze()\n",
        "    x0, y0 = z_where[..., 0, 0], z_where[..., 0, 1]\n",
        "    assert x0.shape == proposed_sim_params[0].shape, f\"x0.shape: {x0.shape}, proposed_sim_params[0].shape: {proposed_sim_params[0].shape}\"\n",
        "    worm_sim = numpyro.handlers.condition(sim_worms, {'L': proposed_sim_params[0], 'A': proposed_sim_params[2], 'T': proposed_sim_params[4], 'kw': proposed_sim_params[6], 'ku': proposed_sim_params[8], 'inc': proposed_sim_params[10], 'dr': proposed_sim_params[12], 'phase_1': proposed_sim_params[14], 'phase_2': proposed_sim_params[16], 'phase_3': proposed_sim_params[18], 'alpha': proposed_sim_params[20], 'x0': x0, 'y0': y0})\n",
        "    worm_trace = numpyro.handlers.trace(worm_sim).get_trace(2, batch_size, T)\n",
        "    worms = worm_trace[\"worms\"][\"value\"]\n",
        "    # print(worms.shape)\n",
        "    print(\"worms.shape\", worms.shape)\n",
        "    print(worms.mean(), worms.std())\n",
        "\n",
        "    digit_recon = self.decode_what(worms)\n",
        "    # print(digit_recon.shape)\n",
        "    print(\"digit_recon.shape\", digit_recon.shape)\n",
        "    frames_recon = embed_digits(digit_recon, z_where, self.frame_size)\n",
        "    # print(frames_recon.shape)\n",
        "    print(\"frames_recon.shape\", frames_recon.shape)\n",
        "    # check for nans\n",
        "    if jnp.any(jnp.isnan(frames_recon)):\n",
        "      print(\"frames_recon has nans\")\n",
        "    if jnp.any(jnp.isnan(digit_recon)):\n",
        "      print(\"digit_recon has nans\")\n",
        "    if jnp.any(jnp.isnan(worms)):\n",
        "      print(\"worms has nans\")\n",
        "      # print the proposed sim params where worms is nan\n",
        "      print(proposed_sim_params[0][jnp.isnan(worms)])\n",
        "    if jnp.any(jnp.isnan(digits)):\n",
        "      print(\"digits has nans\")\n",
        "    if jnp.any(jnp.isnan(frames)):\n",
        "      print(\"frames has nans\")\n",
        "    if jnp.any(jnp.isnan(z_where)):\n",
        "      print(\"z_where has nans\")\n",
        "    return frames_recon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the target and kernels as in Section 6.4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def bmnist_target(network, inputs, batch_size=3, D=2, T=10):\n",
        "   \n",
        "  worms, x0s, y0s = sim_worms(D, batch_size, T)\n",
        "\n",
        "  z_where = []\n",
        "  # worm_frames = []\n",
        "  worm_frames = network.decode_what(worms)\n",
        "  for d in range(D):\n",
        "    z_where_d = []\n",
        "    # z_where_d_t = jnp.array([x0s[d], y0s[d]])\n",
        "    z_where_d_t = jnp.zeros(2)\n",
        "    for t in range(T):\n",
        "      # worm_frame = network.decode_what(worms[..., t, d, :, :])\n",
        "      # worm_frames.append(worm_frame)\n",
        "      scale = 1 if t == 0 else 0.01\n",
        "      z_where_d_t = numpyro.sample(\n",
        "          f\"z_where_{d}_{t}\", dist.Normal(z_where_d_t, scale).to_event(1)\n",
        "      )\n",
        "      z_where_d.append(z_where_d_t)\n",
        "    z_where_d = jnp.stack(z_where_d, -2)\n",
        "    z_where.append(z_where_d)\n",
        "  z_where = jnp.stack(z_where, -3)\n",
        "  z_where = z_where.squeeze()\n",
        "\n",
        "  # print(\"worm_frames target\", worm_frames.shape)\n",
        "  # print(\"z_where target\", z_where.shape)\n",
        "  p = embed_digits(worm_frames, z_where, network.frame_size)\n",
        "  # print(\"p.shape target\", p.shape)\n",
        "  p = dist.util.clamp_probs(p.sum(-4))  # sum across digits\n",
        "  # print(\"summed p.shape target\", p.shape)\n",
        "  # print(\"inputs.shape\", inputs.shape)\n",
        "  frames = numpyro.sample(\"frames\", dist.Bernoulli(p).to_event(3), obs=inputs)\n",
        "\n",
        "  out = {\n",
        "      \"frames\": frames,\n",
        "      \"frames_recon\": p,\n",
        "      \"worms\": worms,\n",
        "      \"worm_frames\": jax.lax.stop_gradient(worm_frames),\n",
        "      **{f\"z_where_{t}\": z_where[..., t, :] for t in range(T)},\n",
        "  }\n",
        "  return (out,)\n",
        "\n",
        "\n",
        "def kernel_where(network, inputs, D=2, t=0, T=10):\n",
        "  if not isinstance(inputs, dict):\n",
        "    # print('making inputs')\n",
        "    inputs = {\n",
        "        \"frames\": inputs,\n",
        "        # \"worm_frames\": jnp.repeat(jnp.expand_dims(network.digit_mean, -3), D, -3),\n",
        "        \"worm_frames\": jnp.tile(network.digit_mean, (T, D, 1, 1)),\n",
        "        \"worms\": jnp.zeros((3, T, D, 6, 2)),\n",
        "    }\n",
        "  else:\n",
        "    pass\n",
        "    # print('inputs already made')\n",
        "\n",
        "  frame = inputs[\"frames\"][..., t, :, :]\n",
        "  z_where_t = []\n",
        "  # print(\"worm_frames where\", inputs[\"worm_frames\"].shape)\n",
        "  # print(\"kernel worm means: \", worm_means.shape)\n",
        "  # print(\"input worm_frames shape\", inputs[\"worm_frames\"].shape)\n",
        "  \n",
        "  # with numpyro.plate('batch', 3, dim=-2):\n",
        "  #   with numpyro.plate('n_worms', D, dim=-1) as d:\n",
        "  #     digit = inputs[\"worm_frames\"][..., d, :, :]\n",
        "  #     x_conv = conv2d(frame, digit)\n",
        "  #     loc, scale = network.encode_where(x_conv, worm_means[..., t, d, :])\n",
        "  #     z_where_d_t = numpyro.sample(\n",
        "  #         f\"z_where_{d}_{t}\", dist.Normal(loc, scale).to_event(1)\n",
        "  #     )\n",
        "  #     z_where_t.append(z_where_d_t)\n",
        "  #     frame_recon = embed_digits(digit, z_where_d_t, network.frame_size)\n",
        "  #     frame = frame - frame_recon\n",
        "  for d in range(D):\n",
        "    worm_frame = inputs[\"worm_frames\"][..., t, d, :, :]\n",
        "    # print(\"worm_frame shape where\", worm_frame.shape)\n",
        "    # print(\"frame shape where\", frame.shape)\n",
        "    x_conv = conv2d(frame, worm_frame)\n",
        "    loc, scale = network.encode_where(x_conv)\n",
        "    z_where_d_t = numpyro.sample(\n",
        "        f\"z_where_{d}_{t}\", dist.Normal(loc, scale).to_event(1)\n",
        "    )\n",
        "    z_where_t.append(z_where_d_t)\n",
        "    frame_recon = embed_digits(worm_frame, z_where_d_t, network.frame_size)\n",
        "    frame = frame - frame_recon\n",
        "  z_where_t = jnp.stack(z_where_t, -2)\n",
        "  z_where_t = z_where_t.squeeze() # this is a hack, there is some confusion with plating - the particle plate adds a singleton dimension\n",
        "  # print(\"z_where_t kernel where\", z_where_t.shape)\n",
        "  out = {**inputs, **{f\"z_where_{t}\": z_where_t}}\n",
        "  return (out,)\n",
        "\n",
        "\n",
        "# def kernel_what(network, inputs, T=10):\n",
        "#   z_where = jnp.stack([inputs[f\"z_where_{t}\"] for t in range(T)], -2)\n",
        "#   digits = crop_frames(inputs[\"frames\"], z_where, 28)\n",
        "#   loc, scale = network.encode_what(digits)\n",
        "#   z_what = numpyro.sample(\"z_what\", dist.Normal(loc, scale).to_event(2))\n",
        "\n",
        "#   out = {**inputs, **{\"z_what\": z_what}}\n",
        "#   return (out,)\n",
        "\n",
        "def kernel_what(network, inputs, T=10):\n",
        "  z_where = jnp.stack([inputs[f\"z_where_{t}\"] for t in range(T)], -2)\n",
        "  z_where = z_where.squeeze() # this is a hack, there is some confusion with plating - the particle plate adds a singleton dimension\n",
        "  # print(\"z_where kernel what\", z_where.shape)\n",
        "  worm_frames = crop_frames(inputs[\"frames\"], z_where, 14)\n",
        "  # print(\"worm_frames what\", worm_frames.shape)\n",
        "  proposed_sim_params = network.encode_what(worm_frames)\n",
        "  loc_L, scale_L, loc_A, scale_A, loc_T, scale_T, loc_kw, scale_kw, loc_ku, scale_ku, loc_inc, scale_inc, loc_dr, scale_dr, loc_phase_1, scale_phase_1, loc_phase_2, scale_phase_2, loc_phase_3, scale_phase_3, loc_alpha, scale_alpha, loc_x0, scale_x0, loc_y0, scale_y0 = proposed_sim_params\n",
        "  # print(\"loc_L\", loc_L.shape)\n",
        "  with numpyro.plate('batch', inputs[\"frames\"].shape[0], dim=-1):\n",
        "    L = numpyro.sample('L', dist.TruncatedNormal(loc_L, scale_L, low=10, high=15).to_event(1))\n",
        "    A = numpyro.sample('A', dist.Normal(loc_A, scale_A).to_event(1))\n",
        "    T = numpyro.sample('T', dist.Normal(loc_T, scale_T).to_event(1))\n",
        "    kw = numpyro.sample('kw', dist.TruncatedNormal(loc_kw, scale_kw, low=0, high=2 * jnp.pi).to_event(1))\n",
        "    ku = numpyro.sample('ku', dist.Normal(loc_ku, scale_ku).to_event(1))\n",
        "    inc = numpyro.sample('inc', dist.TruncatedNormal(loc_inc, scale_inc, low=0, high=2 * jnp.pi).to_event(1))\n",
        "    dr = numpyro.sample('dr', dist.TruncatedNormal(loc_dr, scale_dr, low=0.2, high=0.8).to_event(1))\n",
        "    phase_1 = numpyro.sample('phase_1', dist.TruncatedNormal(loc_phase_1, scale_phase_1, low=0, high=2 * jnp.pi).to_event(1))\n",
        "    phase_2 = numpyro.sample('phase_2', dist.TruncatedNormal(loc_phase_2, scale_phase_2, low=0, high=2 * jnp.pi).to_event(1))\n",
        "    phase_3 = numpyro.sample('phase_3', dist.Normal(loc_phase_3, scale_phase_3).to_event(1))\n",
        "    alpha = numpyro.sample('alpha', dist.Normal(loc_alpha, scale_alpha).to_event(1))\n",
        "    x0 = numpyro.sample('x0', dist.TruncatedNormal(loc_x0, scale_x0, low=-1, high=1).to_event(1))\n",
        "    y0 = numpyro.sample('y0', dist.TruncatedNormal(loc_y0, scale_y0, low=-1, high=1).to_event(1))\n",
        "  # with numpyro.plate('batch', inputs[\"frames\"].shape[0], dim=-2):\n",
        "    # with numpyro.plate('n_worms', 2, dim=-1):\n",
        "\n",
        "    #   L = numpyro.sample('L', dist.TruncatedNormal(loc_L, scale_L, low=10, high=15))\n",
        "    #   A = numpyro.sample('A', dist.Normal(loc_A, scale_A))\n",
        "    #   T = numpyro.sample('T', dist.Normal(loc_T, scale_T))\n",
        "    #   kw = numpyro.sample('kw', dist.TruncatedNormal(loc_kw, scale_kw, low=0, high=2 * jnp.pi))\n",
        "    #   ku = numpyro.sample('ku', dist.Normal(loc_ku, scale_ku))\n",
        "    #   inc = numpyro.sample('inc', dist.TruncatedNormal(loc_inc, scale_inc, low=0, high=2 * jnp.pi))\n",
        "    #   dr = numpyro.sample('dr', dist.TruncatedNormal(loc_dr, scale_dr, low=0.2, high=0.8))\n",
        "    #   phase_1 = numpyro.sample('phase_1', dist.TruncatedNormal(loc_phase_1, scale_phase_1, low=0, high=2 * jnp.pi))\n",
        "    #   phase_2 = numpyro.sample('phase_2', dist.TruncatedNormal(loc_phase_2, scale_phase_2, low=0, high=2 * jnp.pi))\n",
        "    #   phase_3 = numpyro.sample('phase_3', dist.Normal(loc_phase_3, scale_phase_3))\n",
        "    #   alpha = numpyro.sample('alpha', dist.Normal(loc_alpha, scale_alpha))\n",
        "\n",
        "    #   # x0 = numpyro.sample('x0', dist.Delta(inputs[\"z_where_0\"][..., 0]))\n",
        "    #   # y0 = numpyro.sample('y0', dist.Delta(inputs[\"z_where_0\"][..., 1]))\n",
        "    #   x0 = numpyro.sample('x0', dist.Normal(loc_x0, scale_x0))\n",
        "    #   y0 = numpyro.sample('y0', dist.Normal(loc_y0, scale_y0))\n",
        "\n",
        "      # print(\"x0 shape\", x0.shape)\n",
        "\n",
        "  out = {**inputs, **{\"sim_vars\": {'L': L, 'A': A, 'T': T, 'kw': kw, 'ku': ku, 'inc': inc, 'dr': dr, 'phase_1': phase_1, 'phase_2': phase_2, 'phase_3': phase_3, 'alpha': alpha, 'x0': x0, 'y0': y0}}}\n",
        "  return (out,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we create the bmnist inference program, define the loss function,\n",
        "run the training loop, and plot the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def make_bmnist(params, bmnist_net, batch_size=3, T=10, num_sweeps=5, num_particles=10):\n",
        "  network = coix.util.BindModule(bmnist_net, params)\n",
        "  # Add particle dimension and construct a program.\n",
        "  make_particle_plate_0 = lambda: numpyro.plate(\"particle\", num_particles, dim=-2)\n",
        "  make_particle_plate = lambda: numpyro.plate(\"particle\", num_particles, dim=-3)\n",
        "  target = make_particle_plate()(partial(bmnist_target, network, batch_size=batch_size, D=2, T=T))\n",
        "  kernels = []\n",
        "  for t in range(T):\n",
        "    kernels.append(\n",
        "        # make_particle_plate()(partial(kernel_where, network, D=2, t=t))\n",
        "        make_particle_plate_0()(partial(kernel_where, network, D=2, t=t))\n",
        "    )\n",
        "  # kernels.append(make_particle_plate()(partial(kernel_what, network, T=T)))\n",
        "  kernels.append(make_particle_plate_0()(partial(kernel_what, network, T=T)))\n",
        "  program = coix.algo.apgs(target, kernels, num_sweeps=num_sweeps)\n",
        "  return program\n",
        "\n",
        "\n",
        "def loss_fn(params, key, batch, bmnist_net, num_sweeps, num_particles):\n",
        "  # Prepare data for the program.\n",
        "  shuffle_rng, rng_key = random.split(key)\n",
        "  batch = random.permutation(shuffle_rng, batch, axis=1)\n",
        "  T = batch.shape[-3]\n",
        "  batch_size = batch.shape[-4]\n",
        "\n",
        "  # Run the program and get metrics.\n",
        "  program = make_bmnist(params, bmnist_net, batch_size, T, num_sweeps, num_particles)\n",
        "  _, _, metrics = coix.traced_evaluate(program, seed=rng_key)(batch)\n",
        "  for metric_name in [\"log_Z\", \"log_density\", \"loss\"]:\n",
        "    metrics[metric_name] = metrics[metric_name] / batch.shape[0]\n",
        "  return metrics[\"loss\"], metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Args(argparse.Namespace):\n",
        "  batch_size = 6\n",
        "  # batch_size = 16\n",
        "  num_sweeps = 5\n",
        "  num_particles = 10\n",
        "  learning_rate = 1e-4\n",
        "  # num_steps = 20000\n",
        "  num_steps = 8000\n",
        "  device = \"gpu\"\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1722698561.159098  444701 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-08-03 17:22:41.187772: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2024-08-03 17:22:42.505105: W external/xla/xla/service/gpu/nvptx_compiler.cc:836] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version (12.5.82). Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z_where.shape (10, 6, 2, 10, 2)\n",
            "digits.shape (10, 6, 2, 10, 14, 14)\n",
            "(10, 6, 2)\n",
            "worms.shape (10, 6, 2, 10, 6, 2)\n",
            "1.8056235e-05 1.0\n",
            "digit_recon.shape (10, 6, 2, 10, 14, 14)\n",
            "frames_recon.shape (10, 6, 2, 10, 64, 64)\n"
          ]
        }
      ],
      "source": [
        "lr = args.learning_rate\n",
        "num_steps = args.num_steps\n",
        "batch_size = args.batch_size\n",
        "num_sweeps = args.num_sweeps\n",
        "num_particles = args.num_particles\n",
        "\n",
        "train_ds = load_dataset(is_training=True, batch_size=batch_size, n_data=512)\n",
        "\n",
        "test_ds = load_dataset(is_training=False, batch_size=batch_size)\n",
        "digit_mean = get_digit_mean()\n",
        "# scale down digit_mean to half the size\n",
        "digit_mean = jax.image.resize(digit_mean, (14, 14), method=\"cubic\")\n",
        "test_data = next(test_ds)\n",
        "frame_size = test_data.shape[-1]\n",
        "bmnist_net = BMNISTAutoEncoder(digit_mean=digit_mean, frame_size=frame_size)\n",
        "test_data_tiled = np.tile(test_data, ((num_particles,) + ((1,) * test_data.ndim)))\n",
        "init_params = bmnist_net.init(jax.random.PRNGKey(0), test_data_tiled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lr_schedule = cosine_decay_schedule(lr, num_steps, 0.1)\n",
        "lr_schedule = cosine_decay_schedule(lr, num_steps, 1.0)\n",
        "\n",
        "opt = optax.chain(\n",
        "    clip_by_global_norm(100.0),\n",
        "    optax.adam(lr_schedule),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling the first train step...\n",
            "Time to compile a train step: 248.12323021888733\n",
            "=====\n",
            "Step 400  | ess     1.0000 | log_Z -1427526.8750 | log_density -1427574.3750 | loss 77202544.0000 | squared_grad_norm 42845810688.0000\n",
            "Step 800  | ess     1.8507 | log_Z -1497214.0000 | log_density -1497260.5000 | loss 81731688.0000 | squared_grad_norm 85844968.0000\n",
            "Step 1200 | ess     1.2816 | log_Z -1565130.5000 | log_density -1565180.3750 | loss 79757960.0000 | squared_grad_norm 81086816.0000\n",
            "Step 1600 | ess     8.5148 | log_Z -1392441.7500 | log_density -1392487.0000 | loss 81246576.0000 | squared_grad_norm 133708488.0000\n",
            "Step 2000 | ess     5.5946 | log_Z -1747038.2500 | log_density -1747093.7500 | loss 93652464.0000 | squared_grad_norm 51587500.0000\n",
            "Step 2400 | ess     4.9819 | log_Z -2023969.7500 | log_density -2024029.8750 | loss 103317368.0000 | squared_grad_norm 98456936.0000\n",
            "Step 2800 | ess     5.7141 | log_Z -2455309.0000 | log_density -2455369.5000 | loss 122730608.0000 | squared_grad_norm 106137384.0000\n",
            "Step 3200 | ess     4.4591 | log_Z -2993658.7500 | log_density -2993719.5000 | loss 162980160.0000 | squared_grad_norm 26334872.0000\n",
            "Step 3600 | ess     4.1704 | log_Z -3282691.7500 | log_density -3282755.7500 | loss 178766336.0000 | squared_grad_norm 36324664.0000\n",
            "Step 4000 | ess     2.1296 | log_Z -3882632.5000 | log_density -3882705.0000 | loss 189438304.0000 | squared_grad_norm 39150636.0000\n",
            "Step 4400 | ess     2.7523 | log_Z -3967772.7500 | log_density -3967843.7500 | loss 219503328.0000 | squared_grad_norm 13757169.0000\n",
            "Step 4800 | ess     1.2316 | log_Z -5987490.0000 | log_density -5987569.0000 | loss 255045728.0000 | squared_grad_norm 55050160.0000\n",
            "Step 5200 | ess     2.9952 | log_Z -4972532.5000 | log_density -4972609.0000 | loss 254263536.0000 | squared_grad_norm 26360344.0000\n",
            "Step 5600 | ess     7.0455 | log_Z -4538088.0000 | log_density -4538163.5000 | loss 261020096.0000 | squared_grad_norm 87281784.0000\n",
            "Step 6000 | ess     3.0855 | log_Z -4806958.0000 | log_density -4807034.0000 | loss 246078192.0000 | squared_grad_norm 30752820.0000\n",
            "Step 6400 | ess     2.1131 | log_Z -6232921.5000 | log_density -6233003.5000 | loss 278453824.0000 | squared_grad_norm 13831653.0000\n",
            "Step 6800 | ess     2.1741 | log_Z -4974071.0000 | log_density -4974147.5000 | loss 268132160.0000 | squared_grad_norm 9831878.0000\n",
            "Step 7200 | ess     1.1056 | log_Z -4488159.5000 | log_density -4488236.0000 | loss 260595840.0000 | squared_grad_norm 22123648.0000\n",
            "Step 7600 | ess     2.9952 | log_Z -4873091.0000 | log_density -4873174.0000 | loss 263837088.0000 | squared_grad_norm 30147354.0000\n",
            "Step 8000 | ess     3.5251 | log_Z -5073585.5000 | log_density -5073657.0000 | loss 300753888.0000 | squared_grad_norm 34947792.0000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "bmnist_params, _ = coix.util.train(\n",
        "    partial(\n",
        "        loss_fn,\n",
        "        bmnist_net=bmnist_net,\n",
        "        num_sweeps=num_sweeps,\n",
        "        num_particles=num_particles,\n",
        "    ),\n",
        "    init_params,\n",
        "    # optax.adam(lr),\n",
        "    opt,\n",
        "    num_steps,\n",
        "    train_ds,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 10, 64, 64)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load worm_learned_params.npy\n",
        "\n",
        "# bmnist_params = np.load(\"worm_learned_params.npy\", allow_pickle=True).item()\n",
        "\n",
        "np.save(\"worm_learned_params.npy\", bmnist_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "T_test = test_data.shape[-3]\n",
        "batch_size_test = test_data.shape[-4]\n",
        "program = make_bmnist(\n",
        "    bmnist_params, bmnist_net, batch_size_test, T_test, num_sweeps, num_particles\n",
        ")\n",
        "out, _, _ = coix.traced_evaluate(program, seed=jax.random.PRNGKey(1))(\n",
        "    test_data\n",
        ")\n",
        "out = out[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "b = 0\n",
        "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
        "colors = prop_cycle.by_key()[\"color\"]\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "def animate(i):\n",
        "  axes[0].cla()\n",
        "  axes[0].imshow(test_data[b, i])\n",
        "  axes[1].cla()\n",
        "  axes[1].imshow(out[\"frames_recon\"][0, b, i])\n",
        "  for d in range(2):\n",
        "    where = 0.5 * (out[f\"z_where_{i}\"][0, b, d] + 1) * (frame_size - 14) - 0.5\n",
        "    color = colors[d]\n",
        "    axes[0].add_patch(\n",
        "        Rectangle(where, 14, 14, edgecolor=color, lw=3, fill=False)\n",
        "    )\n",
        "plt.rc(\"animation\", html=\"jshtml\")\n",
        "plt.tight_layout()\n",
        "ani = animation.FuncAnimation(fig, animate, frames=range(10), interval=300)\n",
        "writer = animation.PillowWriter(fps=15)\n",
        "ani.save(\"bmnist.gif\", writer=writer)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 0\n",
        "b = 3\n",
        "d = 0\n",
        "where = 0.5 * (out[f\"z_where_{i}\"][0, b, d] + 1) * (frame_size - 14) - 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([0.15286748, 0.44975227], dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out[f\"z_where_{i}\"][0, b, d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([28.321686, 35.74381 ], dtype=float32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "where"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['frames', 'frames_recon', 'worm_frames', 'worms', 'z_where_0', 'z_where_1', 'z_where_2', 'z_where_3', 'z_where_4', 'z_where_5', 'z_where_6', 'z_where_7', 'z_where_8', 'z_where_9'])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "network = coix.util.BindModule(bmnist_net, bmnist_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_z_where = jnp.stack([out[f\"z_where_{i}\"] for i in range(10)], -2)\n",
        "digits = crop_frames(test_data_tiled, out_z_where, 14)\n",
        "gru_out = network.encode_what(digits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[[-0.0036361 , -0.00363905],\n",
              "        [-0.310714  , -0.0036361 ],\n",
              "        [-0.00363863, -0.00363601],\n",
              "        [-0.32819477, -0.01364572],\n",
              "        [-0.00363434, -0.00363863],\n",
              "        [-0.0036361 , -0.00363863]],\n",
              "\n",
              "       [[-0.00363601, -0.0036361 ],\n",
              "        [-0.310714  , -0.00363992],\n",
              "        [-0.00363863, -0.00363601],\n",
              "        [-0.3282078 , -0.01365689],\n",
              "        [-0.00363863, -0.0036361 ],\n",
              "        [-0.0036361 , -0.0036361 ]],\n",
              "\n",
              "       [[-0.0036361 , -0.00363905],\n",
              "        [-0.310714  , -0.0036361 ],\n",
              "        [-0.0036361 , -0.0036361 ],\n",
              "        [-0.32819736, -0.01364578],\n",
              "        [-0.0036361 , -0.0036361 ],\n",
              "        [-0.0036361 , -0.00363905]],\n",
              "\n",
              "       [[-0.00363601, -0.0036361 ],\n",
              "        [-0.310714  , -0.00363863],\n",
              "        [-0.00363905, -0.00363601],\n",
              "        [-0.3282078 , -0.01365689],\n",
              "        [-0.0036361 , -0.00363434],\n",
              "        [-0.00363905, -0.00363863]],\n",
              "\n",
              "       [[-0.00363863, -0.0036361 ],\n",
              "        [-0.310714  , -0.00363863],\n",
              "        [-0.0036361 , -0.00363601],\n",
              "        [-0.32821286, -0.01366351],\n",
              "        [-0.00363905, -0.0036361 ],\n",
              "        [-0.0036361 , -0.0036361 ]],\n",
              "\n",
              "       [[-0.00363434, -0.00363905],\n",
              "        [-0.310714  , -0.0036361 ],\n",
              "        [-0.0036361 , -0.0036361 ],\n",
              "        [-0.32820663, -0.01364578],\n",
              "        [-0.00363905, -0.00363905],\n",
              "        [-0.00363905, -0.00363449]],\n",
              "\n",
              "       [[-0.00363905, -0.0036361 ],\n",
              "        [-0.310714  , -0.00363434],\n",
              "        [-0.0036361 , -0.00363863],\n",
              "        [-0.0036361 , -0.01365689],\n",
              "        [-0.00363905, -0.00363905],\n",
              "        [-0.0036361 , -0.00363863]],\n",
              "\n",
              "       [[-0.0036361 , -0.0036361 ],\n",
              "        [-0.310714  , -0.0036361 ],\n",
              "        [-0.00363863, -0.0036361 ],\n",
              "        [-0.00363905, -0.01364578],\n",
              "        [-0.00363863, -0.00363905],\n",
              "        [-0.00363905, -0.0036361 ]],\n",
              "\n",
              "       [[-0.0036361 , -0.0036361 ],\n",
              "        [-0.310714  , -0.00363905],\n",
              "        [-0.00363863, -0.00363601],\n",
              "        [-0.0036361 , -0.01365758],\n",
              "        [-0.00363863, -0.0036361 ],\n",
              "        [-0.00363905, -0.00363863]],\n",
              "\n",
              "       [[-0.00363905, -0.0036361 ],\n",
              "        [-0.310714  , -0.0036361 ],\n",
              "        [-0.00363863, -0.0036361 ],\n",
              "        [-0.00363863, -0.01366351],\n",
              "        [-0.0036361 , -0.00363905],\n",
              "        [-0.0036361 , -0.0036361 ]]], dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gru_out[24]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[[6.9245462, 6.9245434],\n",
              "        [4.8942523, 6.9245462],\n",
              "        [6.924541 , 6.9245467],\n",
              "        [5.541922 , 7.23274  ],\n",
              "        [6.9245596, 6.924541 ],\n",
              "        [6.9245462, 6.924541 ]],\n",
              "\n",
              "       [[6.9245467, 6.9245462],\n",
              "        [4.8942523, 6.924543 ],\n",
              "        [6.924541 , 6.9245467],\n",
              "        [5.5419173, 7.2327447],\n",
              "        [6.924541 , 6.9245462],\n",
              "        [6.9245462, 6.9245462]],\n",
              "\n",
              "       [[6.9245462, 6.9245434],\n",
              "        [4.8942523, 6.9245462],\n",
              "        [6.9245462, 6.9245462],\n",
              "        [5.541929 , 7.2327385],\n",
              "        [6.9245462, 6.9245462],\n",
              "        [6.9245462, 6.9245434]],\n",
              "\n",
              "       [[6.9245467, 6.9245462],\n",
              "        [4.8942523, 6.924541 ],\n",
              "        [6.9245434, 6.9245467],\n",
              "        [5.5419173, 7.2327447],\n",
              "        [6.9245462, 6.9245596],\n",
              "        [6.9245434, 6.924541 ]],\n",
              "\n",
              "       [[6.924541 , 6.9245462],\n",
              "        [4.8942523, 6.924541 ],\n",
              "        [6.9245462, 6.9245467],\n",
              "        [5.5419335, 7.232744 ],\n",
              "        [6.9245434, 6.9245462],\n",
              "        [6.9245462, 6.9245462]],\n",
              "\n",
              "       [[6.9245596, 6.9245434],\n",
              "        [4.8942523, 6.9245462],\n",
              "        [6.9245462, 6.9245462],\n",
              "        [5.5419273, 7.2327385],\n",
              "        [6.9245434, 6.9245434],\n",
              "        [6.9245434, 6.924558 ]],\n",
              "\n",
              "       [[6.9245434, 6.9245462],\n",
              "        [4.8942523, 6.9245596],\n",
              "        [6.9245462, 6.924541 ],\n",
              "        [6.9245462, 7.2327447],\n",
              "        [6.9245434, 6.9245434],\n",
              "        [6.9245462, 6.924541 ]],\n",
              "\n",
              "       [[6.9245462, 6.9245462],\n",
              "        [4.8942523, 6.9245462],\n",
              "        [6.924541 , 6.9245462],\n",
              "        [6.9245434, 7.2327385],\n",
              "        [6.924541 , 6.9245434],\n",
              "        [6.9245434, 6.9245462]],\n",
              "\n",
              "       [[6.9245462, 6.9245462],\n",
              "        [4.8942523, 6.9245434],\n",
              "        [6.924541 , 6.9245467],\n",
              "        [6.9245462, 7.2327447],\n",
              "        [6.924541 , 6.9245462],\n",
              "        [6.9245434, 6.924541 ]],\n",
              "\n",
              "       [[6.9245434, 6.9245462],\n",
              "        [4.8942523, 6.9245462],\n",
              "        [6.924541 , 6.9245462],\n",
              "        [6.924541 , 7.232744 ],\n",
              "        [6.9245462, 6.9245434],\n",
              "        [6.9245462, 6.9245462]]], dtype=float32)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gru_out[23]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "seeded_kernel_what = numpyro.handlers.seed(kernel_what, jax.random.PRNGKey(0))\n",
        "tr = numpyro.handlers.trace(seeded_kernel_what)(network, out, T=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "duration = 0.55\n",
        "snapshots = 10\n",
        "kpoints = 6\n",
        "box_size = 64\n",
        "\n",
        "sim_fn = partial(\n",
        "    worm_simulation,\n",
        "    duration=duration,\n",
        "    snapshots=snapshots,\n",
        "    kpoints=kpoints,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "worm_out = vmapped_sim_fn(sim_fn, tr[0][\"sim_vars\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array(-0.72237164, dtype=float32)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr[0][\"sim_vars\"][\"x0\"][0, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[-1.6375319 , -4.4281054 ],\n",
              "       [-2.221491  , -2.612232  ],\n",
              "       [-1.8227178 , -0.746921  ],\n",
              "       [-0.7410806 ,  0.8242144 ],\n",
              "       [ 0.48603708,  2.2845519 ],\n",
              "       [ 1.4044651 ,  3.956346  ]], dtype=float32)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "worm_out[0, 0, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([0.7950753 , 0.79507494], dtype=float32)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gru_out[4][0, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[ 0.14297828, -0.6233801 ],\n",
              "       [ 0.25388896, -0.5499334 ],\n",
              "       [ 0.35933933, -0.4691898 ],\n",
              "       [ 0.48430002, -0.3996135 ],\n",
              "       [ 0.6498199 , -0.34233272],\n",
              "       [ 0.8304969 , -0.29280734]], dtype=float32)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out[\"worms\"][0, 0, 0, 3, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a8194019f10>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.imshow(out[\"worm_frames\"][0, 0, 0, 0, :, :])\n",
        "plt.figure()\n",
        "plt.imshow(out[\"worm_frames\"][0, 0, 0, 9, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# network = coix.util.BindModule(bmnist_net, bmnist_params)\n",
        "\n",
        "# out_z_where = jnp.stack([out[f\"z_where_{i}\"] for i in range(10)], -2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
