{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example: Time Series Model - Bouncing MNIST in NumPyro\n",
        "\n",
        "This example illustrates how to construct an inference program based on the APGS\n",
        "sampler [1] for BMNIST. The details of BMNIST can be found in the sections\n",
        "6.4 and F.3 of the reference. We will use the NumPyro (default) backend for this\n",
        "example.\n",
        "\n",
        "**References**\n",
        "\n",
        "    1. Wu, Hao, et al. Amortized population Gibbs samplers with neural\n",
        "       sufficient statistics. ICML 2020.\n",
        "\n",
        "<img src=\"file://../_static/bmnist.gif\" align=\"center\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/frans/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2024-07-25 16:55:05.017710: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-25 16:55:05.042023: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-25 16:55:05.048864: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-25 16:55:06.080209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "from functools import partial\n",
        "\n",
        "import coix\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "from jax import random\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sim_utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's load the moving mnist dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def load_dataset(*, is_training, batch_size):\n",
        "  ds = tfds.load(\"moving_mnist:1.0.0\", split=\"test\")\n",
        "  ds = ds.repeat()\n",
        "  if is_training:\n",
        "    ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "    map_fn = lambda x: x[\"image_sequence\"][..., :10, :, :, 0] / 255\n",
        "  else:\n",
        "    map_fn = lambda x: x[\"image_sequence\"][..., 0] / 255\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.map(map_fn)\n",
        "  return iter(tfds.as_numpy(ds))\n",
        "\n",
        "\n",
        "def get_digit_mean():\n",
        "  ds, ds_info = tfds.load(\"mnist:3.0.1\", split=\"train\", with_info=True)\n",
        "  ds = tfds.as_numpy(ds.batch(ds_info.splits[\"train\"].num_examples))\n",
        "  digit_mean = next(iter(ds))[\"image\"].squeeze(-1).mean(axis=0)\n",
        "  return digit_mean / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we define the neural proposals for the Gibbs kernels and the neural\n",
        "decoder for the generative model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def scale_and_translate(image, where, out_size):\n",
        "  translate = abs(image.shape[-1] - out_size) * (where[..., ::-1] + 1) / 2\n",
        "  return jax.image.scale_and_translate(\n",
        "      image,\n",
        "      (out_size, out_size),\n",
        "      (0, 1),\n",
        "      jnp.ones(2),\n",
        "      translate,\n",
        "      method=\"cubic\",\n",
        "      antialias=False,\n",
        "  )\n",
        "\n",
        "\n",
        "def crop_frames(frames, z_where, digit_size=28):\n",
        "  # frames:           time.frame_size.frame_size\n",
        "  # z_where: (digits).time.2\n",
        "  # out:     (digits).time.digit_size.digit_size\n",
        "  if frames.ndim == 2 and z_where.ndim == 1:\n",
        "    return scale_and_translate(frames, z_where, out_size=digit_size)\n",
        "  elif frames.ndim == 3 and z_where.ndim == 2:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim == 3 and z_where.ndim == 3:\n",
        "    in_axes = (None, 0)\n",
        "  elif frames.ndim == z_where.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim > z_where.ndim:\n",
        "    in_axes = (0, None)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  return jax.vmap(partial(crop_frames, digit_size=digit_size), in_axes)(\n",
        "      frames, z_where\n",
        "  )\n",
        "\n",
        "\n",
        "def embed_digits(digits, z_where, frame_size=64):\n",
        "  # digits:  (digits).      .digit_size.digit_size\n",
        "  # z_where: (digits).(time).2\n",
        "  # out:     (digits).(time).frame_size.frame_size\n",
        "  if digits.ndim == 2 and z_where.ndim == 1:\n",
        "    return scale_and_translate(digits, z_where, out_size=frame_size)\n",
        "  elif digits.ndim == 2 and z_where.ndim == 2:\n",
        "    in_axes = (None, 0)\n",
        "  elif digits.ndim >= z_where.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  return jax.vmap(partial(embed_digits, frame_size=frame_size), in_axes)(\n",
        "      digits, z_where\n",
        "  )\n",
        "\n",
        "\n",
        "def conv2d(frames, digits):\n",
        "  # frames:          (time).frame_size.frame_size\n",
        "  # digits: (digits).      .digit_size.digit_size\n",
        "  # out:    (digits).(time).conv_size .conv_size\n",
        "  if frames.ndim == 2 and digits.ndim == 2:\n",
        "    return jax.scipy.signal.convolve2d(frames, digits, mode=\"valid\")\n",
        "  elif frames.ndim == digits.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim > digits.ndim:\n",
        "    in_axes = (0, None)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  return jax.vmap(conv2d, in_axes=in_axes)(frames, digits)\n",
        "\n",
        "\n",
        "class EncoderWhat(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, digits):\n",
        "    x = digits.reshape(digits.shape[:-2] + (-1,))\n",
        "    x = nn.Dense(400)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = nn.relu(x)\n",
        "\n",
        "    x = x.sum(-2)  # sum/mean across time\n",
        "    loc_raw = nn.Dense(10)(x)\n",
        "    scale_raw = 0.5 * nn.Dense(10)(x)\n",
        "    return loc_raw, jnp.exp(scale_raw)\n",
        "\n",
        "\n",
        "class EncoderWhere(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, frame_conv):\n",
        "    x = frame_conv.reshape(frame_conv.shape[:-2] + (-1,))\n",
        "    x = nn.softmax(x, -1)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = x.reshape(x.shape[:-1] + (2, 100))\n",
        "    x = nn.relu(x)\n",
        "    loc_raw = nn.Dense(2)(x[..., 0, :])\n",
        "    scale_raw = 0.5 * nn.Dense(2)(x[..., 1, :])\n",
        "    return nn.tanh(loc_raw), jnp.exp(scale_raw)\n",
        "\n",
        "\n",
        "class DecoderWhat(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, z_what):\n",
        "    x = nn.Dense(200)(z_what)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(400)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(784)(x)\n",
        "    logits = x.reshape(x.shape[:-1] + (28, 28))\n",
        "    return nn.sigmoid(logits)\n",
        "\n",
        "\n",
        "class BMNISTAutoEncoder(nn.Module):\n",
        "  digit_mean: jnp.ndarray\n",
        "  frame_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.encode_what = EncoderWhat()\n",
        "    self.encode_where = EncoderWhere()\n",
        "    self.decode_what = DecoderWhat()\n",
        "\n",
        "  def __call__(self, frames):\n",
        "    # Heuristic procedure to setup initial parameters.\n",
        "    frames_conv = conv2d(frames, self.digit_mean)\n",
        "    z_where, _ = self.encode_where(frames_conv)\n",
        "\n",
        "    digits = crop_frames(frames, z_where, 28)\n",
        "    z_what, _ = self.encode_what(digits)\n",
        "\n",
        "    digit_recon = self.decode_what(z_what)\n",
        "    frames_recon = embed_digits(digit_recon, z_where, self.frame_size)\n",
        "    return frames_recon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the target and kernels as in Section 6.4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sim_worms(nworms):\n",
        "    duration = 0.55\n",
        "    snapshots = 10\n",
        "    kpoints = 6\n",
        "    box_size = 64\n",
        "    with numpyro.plate('nworms', nworms):\n",
        "        # L = numpyro.sample('L', dist.Uniform(30, 45))\n",
        "        L = numpyro.sample('L', dist.Uniform(10, 15))\n",
        "        A = numpyro.sample('A', dist.Normal(1, 0.1))\n",
        "        T = numpyro.sample('T', dist.Normal(0.8, 0.1))\n",
        "        kw = numpyro.sample('kw', dist.Uniform(0, 2 * jnp.pi))\n",
        "        ku = numpyro.sample('ku', dist.Normal(jnp.pi, 1))\n",
        "        \n",
        "        inc = numpyro.sample('inc', dist.Uniform(0, 2 * jnp.pi))\n",
        "        dr = numpyro.sample('dr', dist.Uniform(0.2, 0.8))\n",
        "        phase_1 = numpyro.sample('phase_1', dist.Uniform(0, 2 * jnp.pi))\n",
        "        phase_2 = numpyro.sample('phase_2', dist.Uniform(0, 2 * jnp.pi))\n",
        "        phase_3 = numpyro.sample('phase_3', dist.Normal(0, 0.1))\n",
        "        alpha = numpyro.sample('alpha', dist.Normal(4, 4))\n",
        "\n",
        "        alpha = jnp.abs(alpha + 1.0)\n",
        "        half_box = box_size // 2\n",
        "        x0 = numpyro.sample('x0', dist.Uniform(-half_box, half_box))\n",
        "        y0 = numpyro.sample('y0', dist.Uniform(-half_box, half_box))\n",
        "\n",
        "        params = {'L': L, 'A': A, 'T': T, 'kw': kw, 'ku': ku, 'inc': inc, 'dr': dr, 'phase_1': phase_1, 'phase_2': phase_2, 'phase_3': phase_3, 'alpha': alpha, 'x0': x0, 'y0': y0}\n",
        "\n",
        "        sim_fn = partial(\n",
        "            worm_simulation,\n",
        "            duration=duration,\n",
        "            snapshots=snapshots,\n",
        "            kpoints=kpoints,\n",
        "        )\n",
        "        worms = jax.vmap(sim_fn, out_axes=1)(params)\n",
        "        worms = worms + half_box\n",
        "        numpyro.deterministic('worms', worms)\n",
        "        return worms, x0, y0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def bmnist_target(network, inputs, D=2, T=10):\n",
        "  worms, x0s, y0s = sim_worms(D)\n",
        "\n",
        "  z_where = []\n",
        "  worm_frames = []\n",
        "  for d in range(D):\n",
        "    z_where_d = []\n",
        "    z_where_d_t = jnp.array([x0s[d], y0s[d]])\n",
        "    for t in range(T):\n",
        "      worm_frame = network.decode_what(worms[..., t, d, :, :])\n",
        "      worm_frames.append(worm_frame)\n",
        "      scale = 1 if t == 0 else 0.1\n",
        "      z_where_d_t = numpyro.sample(\n",
        "          f\"z_where_{d}_{t}\", dist.Normal(z_where_d_t, scale).to_event(1)\n",
        "      )\n",
        "      z_where_d.append(z_where_d_t)\n",
        "    z_where_d = jnp.stack(z_where_d, -2)\n",
        "    z_where.append(z_where_d)\n",
        "  z_where = jnp.stack(z_where, -3)\n",
        "\n",
        "  p = embed_digits(worm_frames, z_where, network.frame_size)\n",
        "  p = dist.util.clamp_probs(p.sum(-4))  # sum across digits\n",
        "  frames = numpyro.sample(\"frames\", dist.Bernoulli(p).to_event(3), obs=inputs)\n",
        "\n",
        "  out = {\n",
        "      \"frames\": frames,\n",
        "      \"frames_recon\": p,\n",
        "      \"worms\": worms,\n",
        "      \"worm_frames\": jax.lax.stop_gradient(worm_frames),\n",
        "      **{f\"z_where_{t}\": z_where[..., t, :] for t in range(T)},\n",
        "  }\n",
        "  return (out,)\n",
        "\n",
        "\n",
        "def kernel_where(network, inputs, D=2, t=0):\n",
        "  if not isinstance(inputs, dict):\n",
        "    inputs = {\n",
        "        \"frames\": inputs,\n",
        "        \"digits\": jnp.repeat(jnp.expand_dims(network.digit_mean, -3), D, -3),\n",
        "    }\n",
        "\n",
        "  frame = inputs[\"frames\"][..., t, :, :]\n",
        "  z_where_t = []\n",
        "  for d in range(D):\n",
        "    digit = inputs[\"digits\"][..., d, :, :]\n",
        "    x_conv = conv2d(frame, digit)\n",
        "    loc, scale = network.encode_where(x_conv)\n",
        "    z_where_d_t = numpyro.sample(\n",
        "        f\"z_where_{d}_{t}\", dist.Normal(loc, scale).to_event(1)\n",
        "    )\n",
        "    z_where_t.append(z_where_d_t)\n",
        "    frame_recon = embed_digits(digit, z_where_d_t, network.frame_size)\n",
        "    frame = frame - frame_recon\n",
        "  z_where_t = jnp.stack(z_where_t, -2)\n",
        "\n",
        "  out = {**inputs, **{f\"z_where_{t}\": z_where_t}}\n",
        "  return (out,)\n",
        "\n",
        "\n",
        "def kernel_what(network, inputs, T=10):\n",
        "  z_where = jnp.stack([inputs[f\"z_where_{t}\"] for t in range(T)], -2)\n",
        "  digits = crop_frames(inputs[\"frames\"], z_where, 28)\n",
        "  loc, scale = network.encode_what(digits)\n",
        "  z_what = numpyro.sample(\"z_what\", dist.Normal(loc, scale).to_event(2))\n",
        "\n",
        "  out = {**inputs, **{\"z_what\": z_what}}\n",
        "  return (out,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we create the bmnist inference program, define the loss function,\n",
        "run the training loop, and plot the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def make_bmnist(params, bmnist_net, T=10, num_sweeps=5, num_particles=10):\n",
        "  network = coix.util.BindModule(bmnist_net, params)\n",
        "  # Add particle dimension and construct a program.\n",
        "  make_particle_plate = lambda: numpyro.plate(\"particle\", num_particles, dim=-2)\n",
        "  target = make_particle_plate()(partial(bmnist_target, network, D=2, T=T))\n",
        "  kernels = []\n",
        "  for t in range(T):\n",
        "    kernels.append(\n",
        "        make_particle_plate()(partial(kernel_where, network, D=2, t=t))\n",
        "    )\n",
        "  kernels.append(make_particle_plate()(partial(kernel_what, network, T=T)))\n",
        "  program = coix.algo.apgs(target, kernels, num_sweeps=num_sweeps)\n",
        "  return program\n",
        "\n",
        "\n",
        "def loss_fn(params, key, batch, bmnist_net, num_sweeps, num_particles):\n",
        "  # Prepare data for the program.\n",
        "  shuffle_rng, rng_key = random.split(key)\n",
        "  batch = random.permutation(shuffle_rng, batch, axis=1)\n",
        "  T = batch.shape[-3]\n",
        "\n",
        "  # Run the program and get metrics.\n",
        "  program = make_bmnist(params, bmnist_net, T, num_sweeps, num_particles)\n",
        "  _, _, metrics = coix.traced_evaluate(program, seed=rng_key)(batch)\n",
        "  for metric_name in [\"log_Z\", \"log_density\", \"loss\"]:\n",
        "    metrics[metric_name] = metrics[metric_name] / batch.shape[0]\n",
        "  return metrics[\"loss\"], metrics\n",
        "\n",
        "\n",
        "def main(args):\n",
        "  lr = args.learning_rate\n",
        "  num_steps = args.num_steps\n",
        "  batch_size = args.batch_size\n",
        "  num_sweeps = args.num_sweeps\n",
        "  num_particles = args.num_particles\n",
        "\n",
        "  train_ds = load_dataset(is_training=True, batch_size=batch_size)\n",
        "  test_ds = load_dataset(is_training=False, batch_size=1)\n",
        "  digit_mean = get_digit_mean()\n",
        "\n",
        "  test_data = next(test_ds)\n",
        "  frame_size = test_data.shape[-1]\n",
        "  bmnist_net = BMNISTAutoEncoder(digit_mean=digit_mean, frame_size=frame_size)\n",
        "  init_params = bmnist_net.init(jax.random.PRNGKey(0), test_data[0])\n",
        "  bmnist_params, _ = coix.util.train(\n",
        "      partial(\n",
        "          loss_fn,\n",
        "          bmnist_net=bmnist_net,\n",
        "          num_sweeps=num_sweeps,\n",
        "          num_particles=num_particles,\n",
        "      ),\n",
        "      init_params,\n",
        "      optax.adam(lr),\n",
        "      num_steps,\n",
        "      train_ds,\n",
        "  )\n",
        "\n",
        "  T_test = test_data.shape[-3]\n",
        "  program = make_bmnist(\n",
        "      bmnist_params, bmnist_net, T_test, num_sweeps, num_particles\n",
        "  )\n",
        "  out, _, _ = coix.traced_evaluate(program, seed=jax.random.PRNGKey(1))(\n",
        "      test_data\n",
        "  )\n",
        "  out = out[0]\n",
        "\n",
        "  prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
        "  colors = prop_cycle.by_key()[\"color\"]\n",
        "  fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "  def animate(i):\n",
        "    axes[0].cla()\n",
        "    axes[0].imshow(test_data[0, i])\n",
        "    axes[1].cla()\n",
        "    axes[1].imshow(out[\"frames_recon\"][0, 0, i])\n",
        "    for d in range(2):\n",
        "      where = 0.5 * (out[f\"z_where_{i}\"][0, 0, d] + 1) * (frame_size - 28) - 0.5\n",
        "      color = colors[d]\n",
        "      axes[0].add_patch(\n",
        "          Rectangle(where, 28, 28, edgecolor=color, lw=3, fill=False)\n",
        "      )\n",
        "\n",
        "  plt.rc(\"animation\", html=\"jshtml\")\n",
        "  plt.tight_layout()\n",
        "  ani = animation.FuncAnimation(fig, animate, frames=range(20), interval=300)\n",
        "  writer = animation.PillowWriter(fps=15)\n",
        "  ani.save(\"bmnist.gif\", writer=writer)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser(description=\"Annealing example\")\n",
        "# parser.add_argument(\"--batch-size\", nargs=\"?\", default=5, type=int)\n",
        "# parser.add_argument(\"--num-sweeps\", nargs=\"?\", default=5, type=int)\n",
        "# parser.add_argument(\"--num_particles\", nargs=\"?\", default=10, type=int)\n",
        "# parser.add_argument(\"--learning-rate\", nargs=\"?\", default=1e-4, type=float)\n",
        "# parser.add_argument(\"--num-steps\", nargs=\"?\", default=20000, type=int)\n",
        "# parser.add_argument(\n",
        "#     \"--device\", default=\"gpu\", type=str, help='use \"cpu\" or \"gpu\".'\n",
        "# )\n",
        "# args = parser.parse_args()\n",
        "\n",
        "class Args(argparse.Namespace):\n",
        "  batch_size = 5\n",
        "  num_sweeps = 5\n",
        "  num_particles = 10\n",
        "  learning_rate = 1e-4\n",
        "  num_steps = 20000\n",
        "  device = \"gpu\"\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1721897624.017737   13005 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-25 10:53:44.076380: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "WARNING:absl:You use TensorFlow DType <dtype: 'uint8'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint8.\n",
            "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
            "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
            "2024-07-25 10:53:44.848364: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/frans/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Dl Completed...: 100%|██████████| 5/5 [00:08<00:00,  1.62s/ file]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset mnist downloaded and prepared to /home/frans/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-25 10:54:02.719347: W external/xla/xla/service/gpu/nvptx_compiler.cc:765] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.5.82). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling the first train step...\n",
            "Time to compile a train step: 200.2943561077118\n",
            "=====\n",
            "Step 1000  | ess     1.0000 | log_Z -18280.3809 | log_density -17428.1465 | loss 869195.6875 | squared_grad_norm 5416568320.0000\n",
            "Step 2000  | ess     1.0000 | log_Z -4616.6055 | log_density -4422.9351 | loss 259741.0312 | squared_grad_norm 2519314944.0000\n",
            "Step 3000  | ess     1.0000 | log_Z -4579.8564 | log_density -4373.5991 | loss 269624.3750 | squared_grad_norm 7288496128.0000\n",
            "Step 4000  | ess     1.0022 | log_Z -8403.9639 | log_density -8225.2324 | loss 542654.8750 | squared_grad_norm 3083183872.0000\n",
            "Step 5000  | ess     1.0118 | log_Z -5174.5366 | log_density -4746.8413 | loss 291925.1562 | squared_grad_norm 2637456384.0000\n",
            "Step 6000  | ess     1.0015 | log_Z -8049.7720 | log_density -7046.3491 | loss 398636.3438 | squared_grad_norm 5364311040.0000\n",
            "Step 7000  | ess     1.0000 | log_Z -7140.5327 | log_density -5145.6582 | loss 533325.1250 | squared_grad_norm 4550688768.0000\n",
            "Step 8000  | ess     1.0007 | log_Z -10909.8174 | log_density -9713.9131 | loss 615634.9375 | squared_grad_norm 1766031104.0000\n",
            "Step 9000  | ess     1.0000 | log_Z -7789.9502 | log_density -7407.2964 | loss 353517.5625 | squared_grad_norm 4196900352.0000\n",
            "Step 10000 | ess     1.0000 | log_Z -5179.6997 | log_density -4441.4043 | loss 384488.7500 | squared_grad_norm 3693563392.0000\n",
            "Step 11000 | ess     1.0006 | log_Z -9081.9092 | log_density -8306.9092 | loss 499063.0938 | squared_grad_norm 5953007616.0000\n",
            "Step 12000 | ess     1.0463 | log_Z -8596.8076 | log_density -7949.5620 | loss 462862.5938 | squared_grad_norm 4981491200.0000\n",
            "Step 13000 | ess     1.0011 | log_Z -4966.2510 | log_density -4490.4580 | loss 352853.0625 | squared_grad_norm 4855380480.0000\n",
            "Step 14000 | ess     1.0000 | log_Z -6568.3345 | log_density -6176.0908 | loss 382350.8125 | squared_grad_norm 5082406400.0000\n",
            "Step 15000 | ess     1.0003 | log_Z -5675.9985 | log_density -4639.5557 | loss 542464.6250 | squared_grad_norm 4885180928.0000\n",
            "Step 16000 | ess     1.0040 | log_Z -7720.5767 | log_density -6747.6460 | loss 511439.4688 | squared_grad_norm 3861069312.0000\n",
            "Step 17000 | ess     1.0000 | log_Z -5532.2983 | log_density -4798.0400 | loss 431039.3125 | squared_grad_norm 2415794176.0000\n",
            "Step 18000 | ess     1.0068 | log_Z -6279.0166 | log_density -5858.4067 | loss 331215.0938 | squared_grad_norm 5334070784.0000\n",
            "Step 19000 | ess     1.0001 | log_Z -5232.0415 | log_density -4214.2666 | loss 335414.8438 | squared_grad_norm 3008694528.0000\n",
            "Step 20000 | ess     1.0327 | log_Z -8944.2637 | log_density -8029.4136 | loss 549122.3750 | squared_grad_norm 5511724032.0000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-25 14:04:52.794191: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "tf.config.experimental.set_visible_devices([], \"GPU\")  # Disable GPU for TF.\n",
        "numpyro.set_platform(args.device)\n",
        "main(args)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
