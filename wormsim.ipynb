{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example: Time Series Model - Bouncing MNIST in NumPyro\n",
        "\n",
        "This example illustrates how to construct an inference program based on the APGS\n",
        "sampler [1] for BMNIST. The details of BMNIST can be found in the sections\n",
        "6.4 and F.3 of the reference. We will use the NumPyro (default) backend for this\n",
        "example.\n",
        "\n",
        "**References**\n",
        "\n",
        "    1. Wu, Hao, et al. Amortized population Gibbs samplers with neural\n",
        "       sufficient statistics. ICML 2020.\n",
        "\n",
        "<img src=\"file://../_static/bmnist.gif\" align=\"center\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/frans/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2024-08-02 11:46:52.933642: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-02 11:46:52.946303: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-02 11:46:52.949684: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-02 11:46:53.473689: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "from functools import partial\n",
        "\n",
        "import coix\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "from jax import random\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "import optax\n",
        "from optax import cosine_decay_schedule\n",
        "from optax import clip_by_global_norm\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sim_utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's load the moving mnist dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# def load_dataset(*, is_training, batch_size):\n",
        "#   ds = tfds.load(\"moving_mnist:1.0.0\", split=\"test\")\n",
        "#   ds = ds.repeat()\n",
        "#   if is_training:\n",
        "#     ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "#     map_fn = lambda x: x[\"image_sequence\"][..., :10, :, :, 0] / 255\n",
        "#   else:\n",
        "#     map_fn = lambda x: x[\"image_sequence\"][..., 0] / 255\n",
        "#   ds = ds.batch(batch_size)\n",
        "#   ds = ds.map(map_fn)\n",
        "#   return iter(tfds.as_numpy(ds))\n",
        "\n",
        "def load_dataset(*, is_training, batch_size):\n",
        "  # ds = np.load(\"worms_train_20k.npy\")\n",
        "  ds = np.load(\"worms_train.npy\")\n",
        "  # make ds a tensor, and batch it\n",
        "  ds = tf.data.Dataset.from_tensor_slices(ds)\n",
        "  ds = ds.repeat()\n",
        "  if is_training:\n",
        "    ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "  ds = ds.batch(batch_size)\n",
        "  return iter(tfds.as_numpy(ds))\n",
        "\n",
        "def get_digit_mean():\n",
        "  ds, ds_info = tfds.load(\"mnist:3.0.1\", split=\"train\", with_info=True)\n",
        "  ds = tfds.as_numpy(ds.batch(ds_info.splits[\"train\"].num_examples))\n",
        "  digit_mean = next(iter(ds))[\"image\"].squeeze(-1).mean(axis=0)\n",
        "  return digit_mean / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we define the neural proposals for the Gibbs kernels and the neural\n",
        "decoder for the generative model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vmapped_sim_fn(sim_fn, params):\n",
        "    # print(jax.tree_map(lambda x: x.shape if hasattr(x, 'shape') else None, params))\n",
        "    if params['L'].ndim == 1:\n",
        "        return jax.vmap(sim_fn, in_axes=0, out_axes=0)(params)\n",
        "    else:\n",
        "        return jax.vmap(partial(vmapped_sim_fn, sim_fn), in_axes=0, out_axes=0)(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sim_worms(nworms, batch_size, n_frames):\n",
        "    duration = 0.55\n",
        "    snapshots = 10\n",
        "    kpoints = 6\n",
        "    box_size = 64\n",
        "    with numpyro.plate('batch', batch_size, dim=-2):\n",
        "        with numpyro.plate('nworms', nworms, dim=-1):\n",
        "            # L = numpyro.sample('L', dist.Uniform(30, 45))\n",
        "            L = numpyro.sample('L', dist.Uniform(10, 15))\n",
        "            A = numpyro.sample('A', dist.Normal(1, 0.1))\n",
        "            T = numpyro.sample('T', dist.Normal(0.8, 0.1))\n",
        "            kw = numpyro.sample('kw', dist.Uniform(0, 2 * jnp.pi))\n",
        "            ku = numpyro.sample('ku', dist.Normal(jnp.pi, 1))\n",
        "            \n",
        "            inc = numpyro.sample('inc', dist.Uniform(0, 2 * jnp.pi))\n",
        "            dr = numpyro.sample('dr', dist.Uniform(0.2, 0.8))\n",
        "            phase_1 = numpyro.sample('phase_1', dist.Uniform(0, 2 * jnp.pi))\n",
        "            phase_2 = numpyro.sample('phase_2', dist.Uniform(0, 2 * jnp.pi))\n",
        "            phase_3 = numpyro.sample('phase_3', dist.Normal(0, 0.1))\n",
        "            alpha = numpyro.sample('alpha', dist.Normal(4, 4))\n",
        "\n",
        "            alpha = jnp.abs(alpha + 1.0)\n",
        "            half_box = box_size // 2\n",
        "            x0 = numpyro.sample('x0', dist.Uniform(-1, 1))\n",
        "            y0 = numpyro.sample('y0', dist.Uniform(-1, 1))\n",
        "            x0 = x0 * half_box\n",
        "            y0 = y0 * half_box\n",
        "\n",
        "            params = {'L': L, 'A': A, 'T': T, 'kw': kw, 'ku': ku, 'inc': inc, 'dr': dr, 'phase_1': phase_1, 'phase_2': phase_2, 'phase_3': phase_3, 'alpha': alpha, 'x0': x0, 'y0': y0}\n",
        "\n",
        "            # # L is a tensor. Assert that all values are within the range\n",
        "            # assert jnp.all(L >= 10) and jnp.all(L <= 15), f\"L: {L}\"\n",
        "            # # kw\n",
        "            # assert jnp.all(kw >= 0) and jnp.all(kw <= 2 * jnp.pi), f\"kw: {kw}\"\n",
        "            # # inc\n",
        "            # assert jnp.all(inc >= 0) and jnp.all(inc <= 2 * jnp.pi), f\"inc: {inc}\"\n",
        "            # # dr\n",
        "            # assert jnp.all(dr >= 0.2) and jnp.all(dr <= 0.8), f\"dr: {dr}\"\n",
        "            # # phase_1\n",
        "            # assert jnp.all(phase_1 >= 0) and jnp.all(phase_1 <= 2 * jnp.pi), f\"phase_1: {phase_1}\"\n",
        "            # # phase_2\n",
        "            # assert jnp.all(phase_2 >= 0) and jnp.all(phase_2 <= 2 * jnp.pi), f\"phase_2: {phase_2}\"\n",
        "            # # x0\n",
        "            # assert jnp.all(x0 >= -1) and jnp.all(x0 <= 1), f\"x0: {x0}\"\n",
        "            # # y0\n",
        "            # assert jnp.all(y0 >= -1) and jnp.all(y0 <= 1), f\"y0: {y0}\"\n",
        "\n",
        "            sim_fn = partial(\n",
        "                worm_simulation,\n",
        "                duration=duration,\n",
        "                snapshots=snapshots,\n",
        "                kpoints=kpoints,\n",
        "            )\n",
        "\n",
        "            with numpyro.plate('n_frames', n_frames):\n",
        "                worms = vmapped_sim_fn(sim_fn, params)\n",
        "                \n",
        "                worms = worms + half_box\n",
        "                numpyro.deterministic('worms', worms)\n",
        "    return worms, x0, y0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def scale_and_translate(image, where, out_size):\n",
        "  translate = abs(image.shape[-1] - out_size) * (where[..., ::-1] + 1) / 2\n",
        "  return jax.image.scale_and_translate(\n",
        "      image,\n",
        "      (out_size, out_size),\n",
        "      (0, 1),\n",
        "      jnp.ones(2),\n",
        "      translate,\n",
        "      method=\"cubic\",\n",
        "      antialias=False,\n",
        "  )\n",
        "\n",
        "\n",
        "def crop_frames(frames, z_where, digit_size=28):\n",
        "  # frames:           time.frame_size.frame_size\n",
        "  # z_where: (digits).time.2\n",
        "  # out:     (digits).time.digit_size.digit_size\n",
        "  if frames.ndim == 2 and z_where.ndim == 1:\n",
        "    return scale_and_translate(frames, z_where, out_size=digit_size)\n",
        "  elif frames.ndim == 3 and z_where.ndim == 2:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim == 3 and z_where.ndim == 3:\n",
        "    in_axes = (None, 0)\n",
        "  elif frames.ndim == z_where.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim > z_where.ndim:\n",
        "    in_axes = (0, None)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  return jax.vmap(partial(crop_frames, digit_size=digit_size), in_axes)(\n",
        "      frames, z_where\n",
        "  )\n",
        "\n",
        "\n",
        "def embed_digits(digits, z_where, frame_size=64):\n",
        "  # digits:  (digits).      .digit_size.digit_size\n",
        "  # z_where: (digits).(time).2\n",
        "  # out:     (digits).(time).frame_size.frame_size\n",
        "  if digits.ndim == 2 and z_where.ndim == 1:\n",
        "    return scale_and_translate(digits, z_where, out_size=frame_size)\n",
        "  elif digits.ndim == 2 and z_where.ndim == 2:\n",
        "    in_axes = (None, 0)\n",
        "  elif digits.ndim >= z_where.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  # print(\"in_axes\", in_axes)\n",
        "  # print(digits.shape)\n",
        "  # print(z_where.shape)\n",
        "  return jax.vmap(partial(embed_digits, frame_size=frame_size), in_axes)(\n",
        "      digits, z_where\n",
        "  )\n",
        "\n",
        "  \n",
        "\n",
        "def conv2d(frames, digits):\n",
        "  # frames:          (time).frame_size.frame_size\n",
        "  # digits: (digits).      .digit_size.digit_size\n",
        "  # out:    (digits).(time).conv_size .conv_size\n",
        "  if frames.ndim == 2 and digits.ndim == 2:\n",
        "    return jax.scipy.signal.convolve2d(frames, digits, mode=\"valid\")\n",
        "  elif frames.ndim == digits.ndim:\n",
        "    in_axes = (0, 0)\n",
        "  elif frames.ndim > digits.ndim:\n",
        "    in_axes = (0, None)\n",
        "  else:\n",
        "    in_axes = (None, 0)\n",
        "  return jax.vmap(conv2d, in_axes=in_axes)(frames, digits)\n",
        "\n",
        "\n",
        "# class EncoderWhat(nn.Module):\n",
        "\n",
        "#   @nn.compact\n",
        "#   def __call__(self, digits):\n",
        "#     x = digits.reshape(digits.shape[:-2] + (-1,)) # flatten frame into vector\n",
        "#     x = nn.Dense(400)(x)\n",
        "#     x = nn.relu(x)\n",
        "#     x = nn.Dense(200)(x)\n",
        "#     x = nn.relu(x)\n",
        "\n",
        "#     x = x.sum(-2)  # sum/mean across time\n",
        "#     loc_raw = nn.Dense(10)(x)\n",
        "#     scale_raw = 0.5 * nn.Dense(10)(x)\n",
        "#     return loc_raw, jnp.exp(scale_raw)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EncoderWhat(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, digits, carry=None):\n",
        "    mappable_dims = digits.shape[:-3]\n",
        "    \n",
        "    hidden_dim = 400\n",
        "\n",
        "    x = digits.reshape(digits.shape[:-2] + (-1,)) # flatten frame into vector\n",
        "    if carry is None:\n",
        "      carry = self.param('carry_init', \n",
        "                         lambda rng, shape: jnp.zeros(shape), \n",
        "                         mappable_dims + (hidden_dim,))\n",
        "    GRU = nn.scan(nn.GRUCell,\n",
        "                  in_axes=-1,\n",
        "                  variable_broadcast='params',\n",
        "                  split_rngs={'params': False}\n",
        "                  )(400)\n",
        "    # print(carry.shape)\n",
        "    # print(x.shape)\n",
        "    # add layernorm\n",
        "    \n",
        "    x = nn.LayerNorm()(x)\n",
        "    x,_ = GRU(carry, x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.LayerNorm()(x)\n",
        "    \n",
        "    x_L = nn.Dense(10)(x)\n",
        "    x_L = nn.relu(x_L)\n",
        "    x_L_loc = nn.Dense(1)(x_L)\n",
        "    # scale to 10-15\n",
        "    x_L_loc = nn.tanh(x_L_loc) * 2.5 + 12.5\n",
        "    x_L_scale = 0.5 * nn.Dense(1)(x_L)\n",
        "\n",
        "    x_A = nn.Dense(10)(x)\n",
        "    x_A = nn.relu(x_A)\n",
        "    x_A_loc = nn.Dense(1)(x_A)\n",
        "    x_A_scale = 0.5 * nn.Dense(1)(x_A)\n",
        "\n",
        "    x_T = nn.Dense(10)(x)\n",
        "    x_T = nn.relu(x_T)\n",
        "    x_T_loc = nn.Dense(1)(x_T)\n",
        "    # constrain to positive\n",
        "    x_T_loc = nn.softplus(x_T_loc)\n",
        "    x_T_scale = 0.5 * nn.Dense(1)(x_T)\n",
        "\n",
        "    x_kw = nn.Dense(10)(x)\n",
        "    x_kw = nn.relu(x_kw)\n",
        "    x_kw_loc = nn.Dense(1)(x_kw)\n",
        "    # scale to 0-2pi\n",
        "    x_kw_loc = nn.tanh(x_kw_loc) * jnp.pi + jnp.pi\n",
        "    x_kw_scale = 0.5 * nn.Dense(1)(x_kw)\n",
        "\n",
        "    x_ku = nn.Dense(10)(x)\n",
        "    x_ku = nn.relu(x_ku)\n",
        "    x_ku_loc = nn.Dense(1)(x_ku)\n",
        "    x_ku_scale = 0.5 * nn.Dense(1)(x_ku)\n",
        "\n",
        "    x_inc = nn.Dense(10)(x)\n",
        "    x_inc = nn.relu(x_inc)\n",
        "    x_inc_loc = nn.Dense(1)(x_inc)\n",
        "    # scale to 0-2pi\n",
        "    x_inc_loc = nn.tanh(x_inc_loc) * jnp.pi + jnp.pi\n",
        "    x_inc_scale = 0.5 * nn.Dense(1)(x_inc)\n",
        "\n",
        "    x_dr = nn.Dense(10)(x)\n",
        "    x_dr = nn.relu(x_dr)\n",
        "    x_dr_loc = nn.Dense(1)(x_dr)\n",
        "    # scale to 0.2-0.8\n",
        "    x_dr_loc = nn.tanh(x_dr_loc) * 0.3 + 0.5\n",
        "    x_dr_scale = 0.5 * nn.Dense(1)(x_dr)\n",
        "\n",
        "    x_phase_1 = nn.Dense(10)(x)\n",
        "    x_phase_1 = nn.relu(x_phase_1)\n",
        "    x_phase_1_loc = nn.Dense(1)(x_phase_1)\n",
        "    # scale to 0-2pi\n",
        "    x_phase_1_loc = nn.tanh(x_phase_1_loc) * jnp.pi + jnp.pi\n",
        "    x_phase_1_scale = 0.5 * nn.Dense(1)(x_phase_1)\n",
        "\n",
        "    x_phase_2 = nn.Dense(10)(x)\n",
        "    x_phase_2 = nn.relu(x_phase_2)\n",
        "    x_phase_2_loc = nn.Dense(1)(x_phase_2)\n",
        "    # scale to 0-2pi\n",
        "    x_phase_2_loc = nn.tanh(x_phase_2_loc) * jnp.pi + jnp.pi\n",
        "    x_phase_2_scale = 0.5 * nn.Dense(1)(x_phase_2)\n",
        "\n",
        "    x_phase_3 = nn.Dense(10)(x)\n",
        "    x_phase_3 = nn.relu(x_phase_3)\n",
        "    x_phase_3_loc = nn.Dense(1)(x_phase_3)\n",
        "    x_phase_3_scale = 0.5 * nn.Dense(1)(x_phase_3)\n",
        "\n",
        "    x_alpha = nn.Dense(10)(x)\n",
        "    x_alpha = nn.relu(x_alpha)\n",
        "    x_alpha_loc = nn.Dense(1)(x_alpha)\n",
        "    x_alpha_scale = 0.5 * nn.Dense(1)(x_alpha)\n",
        "\n",
        "    # return x_L_loc, jnp.exp(x_L_scale), x_A_loc, jnp.exp(x_A_scale), x_T_loc, jnp.exp(x_T_scale), x_kw_loc, jnp.exp(x_kw_scale), x_ku_loc, jnp.exp(x_ku_scale), x_inc_loc, jnp.exp(x_inc_scale), x_dr_loc, jnp.exp(x_dr_scale), x_phase_1_loc, jnp.exp(x_phase_1_scale), x_phase_2_loc, jnp.exp(x_phase_2_scale), x_phase_3_loc, jnp.exp(x_phase_3_scale), x_alpha_loc, jnp.exp(x_alpha_scale)\n",
        "    return x_L_loc.squeeze(-1), jnp.exp(x_L_scale.squeeze(-1)), x_A_loc.squeeze(-1), jnp.exp(x_A_scale.squeeze(-1)), x_T_loc.squeeze(-1), jnp.exp(x_T_scale.squeeze(-1)), x_kw_loc.squeeze(-1), jnp.exp(x_kw_scale.squeeze(-1)), x_ku_loc.squeeze(-1), jnp.exp(x_ku_scale.squeeze(-1)), x_inc_loc.squeeze(-1), jnp.exp(x_inc_scale.squeeze(-1)), x_dr_loc.squeeze(-1), jnp.exp(x_dr_scale.squeeze(-1)), x_phase_1_loc.squeeze(-1), jnp.exp(x_phase_1_scale.squeeze(-1)), x_phase_2_loc.squeeze(-1), jnp.exp(x_phase_2_scale.squeeze(-1)), x_phase_3_loc.squeeze(-1), jnp.exp(x_phase_3_scale.squeeze(-1)), x_alpha_loc.squeeze(-1), jnp.exp(x_alpha_scale.squeeze(-1))\n",
        "\n",
        "\n",
        "\n",
        "# class EncoderWhere(nn.Module):\n",
        "\n",
        "#   @nn.compact\n",
        "#   def __call__(self, frame_conv):\n",
        "#     x = frame_conv.reshape(frame_conv.shape[:-2] + (-1,))\n",
        "#     x = nn.softmax(x, -1)\n",
        "#     x = nn.Dense(200)(x)\n",
        "#     x = nn.relu(x)\n",
        "#     x = nn.Dense(200)(x)\n",
        "#     x = x.reshape(x.shape[:-1] + (2, 100))\n",
        "#     x = nn.relu(x)\n",
        "#     loc_raw = nn.Dense(2)(x[..., 0, :])\n",
        "#     scale_raw = 0.5 * nn.Dense(2)(x[..., 1, :])\n",
        "#     return nn.tanh(loc_raw), jnp.exp(scale_raw)\n",
        "\n",
        "class EncoderWhere(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, frame_conv, worm_means = None):\n",
        "    x = frame_conv.reshape(frame_conv.shape[:-2] + (-1,))\n",
        "    # concatenate worm_means to x\n",
        "    if worm_means is None:\n",
        "      worm_means = jnp.zeros(x.shape[:-1] + (2,))\n",
        "    x = jnp.concatenate([x, jnp.zeros(x.shape[:-1] + (1,))], axis=-1)\n",
        "    x = nn.softmax(x, -1)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = x.reshape(x.shape[:-1] + (2, 100))\n",
        "    x = nn.relu(x)\n",
        "    loc_raw = nn.Dense(2)(x[..., 0, :])\n",
        "    scale_raw = 0.5 * nn.Dense(2)(x[..., 1, :])\n",
        "    return nn.tanh(loc_raw), jnp.exp(scale_raw)\n",
        "\n",
        "\n",
        "class DecoderWhat(nn.Module):\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, z_what):\n",
        "    x = z_what.reshape(z_what.shape[:-2] + (-1,)) # flatten knots x 2 into vector\n",
        "    x = nn.Dense(200)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(400)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(784)(x)\n",
        "    logits = x.reshape(x.shape[:-1] + (28, 28))\n",
        "    return nn.sigmoid(logits)\n",
        "\n",
        "\n",
        "class BMNISTAutoEncoder(nn.Module):\n",
        "  digit_mean: jnp.ndarray\n",
        "  frame_size: int\n",
        "\n",
        "  def setup(self):\n",
        "    self.encode_what = EncoderWhat()\n",
        "    self.encode_where = EncoderWhere()\n",
        "    self.decode_what = DecoderWhat()\n",
        "\n",
        "  def __call__(self, frames):\n",
        "    num_particles, batch_size, T, frame_size, frame_size = frames.shape\n",
        "    # Heuristic procedure to setup initial parameters.\n",
        "\n",
        "    z_where = []\n",
        "    for t in range(10):\n",
        "      frame = frames[..., t, :, :]\n",
        "      z_where_d = []\n",
        "      for d in range(2):\n",
        "        frames_conv = conv2d(frame, self.digit_mean)\n",
        "        z_where_t_d, _ = self.encode_where(frames_conv)\n",
        "        z_where_d.append(z_where_t_d)\n",
        "      z_where_d = jnp.stack(z_where_d, -2)\n",
        "      z_where.append(z_where_d)\n",
        "    # z_where = jnp.stack(z_where, -3).transpose(0, 2, 1, 3)\n",
        "    z_where = jnp.stack(z_where, -3).transpose(0, 1, 3, 2, 4)\n",
        "    print(z_where.shape)\n",
        "    digits = crop_frames(frames, z_where, 28)\n",
        "    print(digits.shape)\n",
        "    # z_what, _ = self.encode_what(digits)\n",
        "    proposed_sim_params = self.encode_what(digits)\n",
        "    print(proposed_sim_params[0].shape)\n",
        "    # proposed_sim_params = jax.tree_map(lambda x: x.squeeze(-1), proposed_sim_params)\n",
        "    # x0, y0 = z_where[..., 0, 0].squeeze(), z_where[..., 0, 1].squeeze()\n",
        "    x0, y0 = z_where[..., 0, 0], z_where[..., 0, 1]\n",
        "    assert x0.shape == proposed_sim_params[0].shape, f\"x0.shape: {x0.shape}, proposed_sim_params[0].shape: {proposed_sim_params[0].shape}\"\n",
        "    worm_sim = numpyro.handlers.condition(sim_worms, {'L': proposed_sim_params[0], 'A': proposed_sim_params[2], 'T': proposed_sim_params[4], 'kw': proposed_sim_params[6], 'ku': proposed_sim_params[8], 'inc': proposed_sim_params[10], 'dr': proposed_sim_params[12], 'phase_1': proposed_sim_params[14], 'phase_2': proposed_sim_params[16], 'phase_3': proposed_sim_params[18], 'alpha': proposed_sim_params[20], 'x0': x0, 'y0': y0})\n",
        "    worm_trace = numpyro.handlers.trace(worm_sim).get_trace(2, batch_size, T)\n",
        "    worms = worm_trace[\"worms\"][\"value\"]\n",
        "    print(worms.shape)\n",
        "\n",
        "    digit_recon = self.decode_what(worms)\n",
        "    print(digit_recon.shape)\n",
        "    frames_recon = embed_digits(digit_recon, z_where, self.frame_size)\n",
        "    print(frames_recon.shape)\n",
        "    # check for nans\n",
        "    if jnp.any(jnp.isnan(frames_recon)):\n",
        "      print(\"frames_recon has nans\")\n",
        "    if jnp.any(jnp.isnan(digit_recon)):\n",
        "      print(\"digit_recon has nans\")\n",
        "    if jnp.any(jnp.isnan(worms)):\n",
        "      print(\"worms has nans\")\n",
        "      # print the proposed sim params where worms is nan\n",
        "      print(proposed_sim_params[0][jnp.isnan(worms)])\n",
        "    if jnp.any(jnp.isnan(digits)):\n",
        "      print(\"digits has nans\")\n",
        "    if jnp.any(jnp.isnan(frames)):\n",
        "      print(\"frames has nans\")\n",
        "    if jnp.any(jnp.isnan(z_where)):\n",
        "      print(\"z_where has nans\")\n",
        "    return frames_recon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we define the target and kernels as in Section 6.4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def bmnist_target(network, inputs, batch_size=3, D=2, T=10):\n",
        "   \n",
        "  worms, x0s, y0s = sim_worms(D, batch_size, T)\n",
        "\n",
        "  z_where = []\n",
        "  # worm_frames = []\n",
        "  worm_frames = network.decode_what(worms)\n",
        "  for d in range(D):\n",
        "    z_where_d = []\n",
        "    # z_where_d_t = jnp.array([x0s[d], y0s[d]])\n",
        "    z_where_d_t = jnp.zeros(2)\n",
        "    for t in range(T):\n",
        "      # worm_frame = network.decode_what(worms[..., t, d, :, :])\n",
        "      # worm_frames.append(worm_frame)\n",
        "      scale = 1 if t == 0 else 0.1\n",
        "      z_where_d_t = numpyro.sample(\n",
        "          f\"z_where_{d}_{t}\", dist.Normal(z_where_d_t, scale).to_event(1)\n",
        "      )\n",
        "      z_where_d.append(z_where_d_t)\n",
        "    z_where_d = jnp.stack(z_where_d, -2)\n",
        "    z_where.append(z_where_d)\n",
        "  z_where = jnp.stack(z_where, -3)\n",
        "  z_where = z_where.squeeze() # this is a hack, there is some confusion with plating - the particle plate adds a singleton dimension\n",
        "\n",
        "  # print(\"worm_frames target\", worm_frames.shape)\n",
        "  # print(\"z_where target\", z_where.shape)\n",
        "  p = embed_digits(worm_frames, z_where, network.frame_size)\n",
        "  # print(\"p.shape target\", p.shape)\n",
        "  p = dist.util.clamp_probs(p.sum(-4))  # sum across digits\n",
        "  # print(\"summed p.shape target\", p.shape)\n",
        "  # print(\"inputs.shape\", inputs.shape)\n",
        "  frames = numpyro.sample(\"frames\", dist.Bernoulli(p).to_event(3), obs=inputs)\n",
        "\n",
        "  out = {\n",
        "      \"frames\": frames,\n",
        "      \"frames_recon\": p,\n",
        "      \"worms\": worms,\n",
        "      \"worm_frames\": jax.lax.stop_gradient(worm_frames),\n",
        "      **{f\"z_where_{t}\": z_where[..., t, :] for t in range(T)},\n",
        "  }\n",
        "  return (out,)\n",
        "\n",
        "\n",
        "def kernel_where(network, inputs, D=2, t=0, T=10):\n",
        "  if not isinstance(inputs, dict):\n",
        "    # print('making inputs')\n",
        "    inputs = {\n",
        "        \"frames\": inputs,\n",
        "        # \"worm_frames\": jnp.repeat(jnp.expand_dims(network.digit_mean, -3), D, -3),\n",
        "        \"worm_frames\": jnp.tile(network.digit_mean, (T, D, 1, 1)),\n",
        "        \"worms\": jnp.zeros((3, T, D, 6, 2)),\n",
        "    }\n",
        "  else:\n",
        "    pass\n",
        "    # print('inputs already made')\n",
        "\n",
        "  frame = inputs[\"frames\"][..., t, :, :]\n",
        "  z_where_t = []\n",
        "  worm_means = inputs[\"worms\"].mean(-2)\n",
        "  # print(\"worm_frames where\", inputs[\"worm_frames\"].shape)\n",
        "  # print(\"kernel worm means: \", worm_means.shape)\n",
        "  # print(\"input worm_frames shape\", inputs[\"worm_frames\"].shape)\n",
        "  \n",
        "  # with numpyro.plate('batch', 3, dim=-2):\n",
        "  #   with numpyro.plate('n_worms', D, dim=-1) as d:\n",
        "  #     digit = inputs[\"worm_frames\"][..., d, :, :]\n",
        "  #     x_conv = conv2d(frame, digit)\n",
        "  #     loc, scale = network.encode_where(x_conv, worm_means[..., t, d, :])\n",
        "  #     z_where_d_t = numpyro.sample(\n",
        "  #         f\"z_where_{d}_{t}\", dist.Normal(loc, scale).to_event(1)\n",
        "  #     )\n",
        "  #     z_where_t.append(z_where_d_t)\n",
        "  #     frame_recon = embed_digits(digit, z_where_d_t, network.frame_size)\n",
        "  #     frame = frame - frame_recon\n",
        "  for d in range(D):\n",
        "    worm_frame = inputs[\"worm_frames\"][..., t, d, :, :]\n",
        "    # print(\"worm_frame shape where\", worm_frame.shape)\n",
        "    # print(\"frame shape where\", frame.shape)\n",
        "    x_conv = conv2d(frame, worm_frame)\n",
        "    loc, scale = network.encode_where(x_conv, worm_means[..., t, d, :])\n",
        "    z_where_d_t = numpyro.sample(\n",
        "        f\"z_where_{d}_{t}\", dist.Normal(loc, scale).to_event(1)\n",
        "    )\n",
        "    z_where_t.append(z_where_d_t)\n",
        "    frame_recon = embed_digits(worm_frame, z_where_d_t, network.frame_size)\n",
        "    frame = frame - frame_recon\n",
        "  z_where_t = jnp.stack(z_where_t, -2)\n",
        "  z_where_t = z_where_t.squeeze() # this is a hack, there is some confusion with plating - the particle plate adds a singleton dimension\n",
        "  # print(\"z_where_t kernel where\", z_where_t.shape)\n",
        "  out = {**inputs, **{f\"z_where_{t}\": z_where_t}}\n",
        "  return (out,)\n",
        "\n",
        "\n",
        "# def kernel_what(network, inputs, T=10):\n",
        "#   z_where = jnp.stack([inputs[f\"z_where_{t}\"] for t in range(T)], -2)\n",
        "#   digits = crop_frames(inputs[\"frames\"], z_where, 28)\n",
        "#   loc, scale = network.encode_what(digits)\n",
        "#   z_what = numpyro.sample(\"z_what\", dist.Normal(loc, scale).to_event(2))\n",
        "\n",
        "#   out = {**inputs, **{\"z_what\": z_what}}\n",
        "#   return (out,)\n",
        "\n",
        "def kernel_what(network, inputs, T=10):\n",
        "  z_where = jnp.stack([inputs[f\"z_where_{t}\"] for t in range(T)], -2)\n",
        "  z_where = z_where.squeeze() # this is a hack, there is some confusion with plating - the particle plate adds a singleton dimension\n",
        "  # print(\"z_where kernel what\", z_where.shape)\n",
        "  worm_frames = crop_frames(inputs[\"frames\"], z_where, 28)\n",
        "  # print(\"worm_frames what\", worm_frames.shape)\n",
        "  proposed_sim_params = network.encode_what(worm_frames)\n",
        "  loc_L, scale_L, loc_A, scale_A, loc_T, scale_T, loc_kw, scale_kw, loc_ku, scale_ku, loc_inc, scale_inc, loc_dr, scale_dr, loc_phase_1, scale_phase_1, loc_phase_2, scale_phase_2, loc_phase_3, scale_phase_3, loc_alpha, scale_alpha = proposed_sim_params\n",
        "  # print(\"loc_L\", loc_L.shape)\n",
        "  with numpyro.plate('batch', inputs[\"frames\"].shape[0], dim=-2):\n",
        "    with numpyro.plate('n_worms', 2, dim=-1):\n",
        "\n",
        "      L = numpyro.sample('L', dist.TruncatedNormal(loc_L, scale_L, low=10, high=15))\n",
        "      A = numpyro.sample('A', dist.Normal(loc_A, scale_A))\n",
        "      T = numpyro.sample('T', dist.Normal(loc_T, scale_T))\n",
        "      kw = numpyro.sample('kw', dist.TruncatedNormal(loc_kw, scale_kw, low=0, high=2 * jnp.pi))\n",
        "      ku = numpyro.sample('ku', dist.Normal(loc_ku, scale_ku))\n",
        "      inc = numpyro.sample('inc', dist.TruncatedNormal(loc_inc, scale_inc, low=0, high=2 * jnp.pi))\n",
        "      dr = numpyro.sample('dr', dist.TruncatedNormal(loc_dr, scale_dr, low=0.2, high=0.8))\n",
        "      phase_1 = numpyro.sample('phase_1', dist.TruncatedNormal(loc_phase_1, scale_phase_1, low=0, high=2 * jnp.pi))\n",
        "      phase_2 = numpyro.sample('phase_2', dist.TruncatedNormal(loc_phase_2, scale_phase_2, low=0, high=2 * jnp.pi))\n",
        "      phase_3 = numpyro.sample('phase_3', dist.Normal(loc_phase_3, scale_phase_3))\n",
        "      alpha = numpyro.sample('alpha', dist.Normal(loc_alpha, scale_alpha))\n",
        "\n",
        "      # x0 = numpyro.sample('x0', dist.Delta(inputs[\"z_where_0\"][..., 0]))\n",
        "      # y0 = numpyro.sample('y0', dist.Delta(inputs[\"z_where_0\"][..., 1]))\n",
        "      x0 = numpyro.sample('x0', dist.Normal(inputs[\"z_where_0\"][..., 0], 0.1))\n",
        "      y0 = numpyro.sample('y0', dist.Normal(inputs[\"z_where_0\"][..., 1], 0.1))\n",
        "\n",
        "      # print(\"x0 shape\", x0.shape)\n",
        "\n",
        "  out = {**inputs, **{\"sim_vars\": {'L': L, 'A': A, 'T': T, 'kw': kw, 'ku': ku, 'inc': inc, 'dr': dr, 'phase_1': phase_1, 'phase_2': phase_2, 'phase_3': phase_3, 'alpha': alpha, 'x0': x0, 'y0': y0}}}\n",
        "  return (out,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we create the bmnist inference program, define the loss function,\n",
        "run the training loop, and plot the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def make_bmnist(params, bmnist_net, batch_size=3, T=10, num_sweeps=5, num_particles=10):\n",
        "  network = coix.util.BindModule(bmnist_net, params)\n",
        "  # Add particle dimension and construct a program.\n",
        "  make_particle_plate_0 = lambda: numpyro.plate(\"particle\", num_particles, dim=-2)\n",
        "  make_particle_plate = lambda: numpyro.plate(\"particle\", num_particles, dim=-3)\n",
        "  target = make_particle_plate()(partial(bmnist_target, network, batch_size=batch_size, D=2, T=T))\n",
        "  kernels = []\n",
        "  for t in range(T):\n",
        "    kernels.append(\n",
        "        # make_particle_plate()(partial(kernel_where, network, D=2, t=t))\n",
        "        make_particle_plate_0()(partial(kernel_where, network, D=2, t=t))\n",
        "    )\n",
        "  kernels.append(make_particle_plate()(partial(kernel_what, network, T=T)))\n",
        "  program = coix.algo.apgs(target, kernels, num_sweeps=num_sweeps)\n",
        "  return program\n",
        "\n",
        "\n",
        "def loss_fn(params, key, batch, bmnist_net, num_sweeps, num_particles):\n",
        "  # Prepare data for the program.\n",
        "  shuffle_rng, rng_key = random.split(key)\n",
        "  batch = random.permutation(shuffle_rng, batch, axis=1)\n",
        "  T = batch.shape[-3]\n",
        "  batch_size = batch.shape[-4]\n",
        "\n",
        "  # Run the program and get metrics.\n",
        "  program = make_bmnist(params, bmnist_net, batch_size, T, num_sweeps, num_particles)\n",
        "  _, _, metrics = coix.traced_evaluate(program, seed=rng_key)(batch)\n",
        "  for metric_name in [\"log_Z\", \"log_density\", \"loss\"]:\n",
        "    metrics[metric_name] = metrics[metric_name] / batch.shape[0]\n",
        "  return metrics[\"loss\"], metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Args(argparse.Namespace):\n",
        "  batch_size = 5\n",
        "  # batch_size = 3\n",
        "  num_sweeps = 5\n",
        "  num_particles = 10\n",
        "  learning_rate = 1e-4\n",
        "  num_steps = 20000\n",
        "  # num_steps = 200\n",
        "  device = \"gpu\"\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1722592017.719727  157066 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-08-02 11:46:57.747882: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2024-08-02 11:46:58.796160: W external/xla/xla/service/gpu/nvptx_compiler.cc:836] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version (12.5.82). Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 5, 2, 10, 2)\n",
            "(10, 5, 2, 10, 28, 28)\n",
            "(10, 5, 2)\n",
            "(10, 5, 2, 10, 6, 2)\n",
            "(10, 5, 2, 10, 28, 28)\n",
            "(10, 5, 2, 10, 64, 64)\n"
          ]
        }
      ],
      "source": [
        "lr = args.learning_rate\n",
        "num_steps = args.num_steps\n",
        "batch_size = args.batch_size\n",
        "num_sweeps = args.num_sweeps\n",
        "num_particles = args.num_particles\n",
        "\n",
        "train_ds = load_dataset(is_training=True, batch_size=batch_size)\n",
        "\n",
        "test_ds = load_dataset(is_training=False, batch_size=batch_size)\n",
        "digit_mean = get_digit_mean()\n",
        "test_data = next(test_ds)\n",
        "frame_size = test_data.shape[-1]\n",
        "bmnist_net = BMNISTAutoEncoder(digit_mean=digit_mean, frame_size=frame_size)\n",
        "test_data_tiled = np.tile(test_data, ((num_particles,) + ((1,) * test_data.ndim)))\n",
        "init_params = bmnist_net.init(jax.random.PRNGKey(0), test_data_tiled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_schedule = cosine_decay_schedule(lr, num_steps, 0.01)\n",
        "\n",
        "opt = optax.chain(\n",
        "    clip_by_global_norm(1.0),\n",
        "    optax.adam(lr_schedule),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling the first train step...\n"
          ]
        },
        {
          "ename": "TracerBoolConversionError",
          "evalue": "Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function step_fn at /home/frans/.local/lib/python3.12/site-packages/coix/util.py:160 for jit. This concrete value was not available in Python because it depends on the values of the arguments params['params']['encode_what']['Dense_0']['bias'], params['params']['encode_what']['Dense_0']['kernel'], params['params']['encode_what']['Dense_1']['bias'], params['params']['encode_what']['Dense_1']['kernel'], params['params']['encode_what']['Dense_2']['bias'], params['params']['encode_what']['Dense_2']['kernel'], params['params']['encode_what']['Dense_3']['bias'], params['params']['encode_what']['Dense_3']['kernel'], params['params']['encode_what']['LayerNorm_0']['bias'], params['params']['encode_what']['LayerNorm_0']['scale'], params['params']['encode_what']['LayerNorm_1']['bias'], params['params']['encode_what']['LayerNorm_1']['scale'], params['params']['encode_what']['ScanGRUCell_0']['hn']['bias'], params['params']['encode_what']['ScanGRUCell_0']['hn']['kernel'], params['params']['encode_what']['ScanGRUCell_0']['hr']['kernel'], params['params']['encode_what']['ScanGRUCell_0']['hz']['kernel'], params['params']['encode_what']['ScanGRUCell_0']['in']['bias'], params['params']['encode_what']['ScanGRUCell_0']['in']['kernel'], params['params']['encode_what']['ScanGRUCell_0']['ir']['bias'], params['params']['encode_what']['ScanGRUCell_0']['ir']['kernel'], params['params']['encode_what']['ScanGRUCell_0']['iz']['bias'], params['params']['encode_what']['ScanGRUCell_0']['iz']['kernel'], params['params']['encode_what']['carry_init'], params['params']['encode_where']['Dense_0']['bias'], params['params']['encode_where']['Dense_0']['kernel'], params['params']['encode_where']['Dense_1']['bias'], params['params']['encode_where']['Dense_1']['kernel'], params['params']['encode_where']['Dense_2']['bias'], params['params']['encode_where']['Dense_2']['kernel'], params['params']['encode_where']['Dense_3']['bias'], params['params']['encode_where']['Dense_3']['kernel'], args[0], and args[1].\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bmnist_params, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcoix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbmnist_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbmnist_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_sweeps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_sweeps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_particles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_particles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# optax.adam(lr),\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/util.py:204\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loss_fn, init_params, optimizer, num_steps, dataloader, seed, jit_compile, eval_fn, log_every, init_step, opt_state, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m key \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mfold_in(run_key, step)\n\u001b[1;32m    203\u001b[0m args \u001b[38;5;241m=\u001b[39m (key, \u001b[38;5;28mnext\u001b[39m(dataloader)) \u001b[38;5;28;01mif\u001b[39;00m dataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (key,)\n\u001b[0;32m--> 204\u001b[0m params, opt_state, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_jitted_step_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    208\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m metrics:\n",
            "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/util.py:161\u001b[0m, in \u001b[0;36mtrain.<locals>.step_fn\u001b[0;34m(params, opt_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_fn\u001b[39m(params, opt_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 161\u001b[0m   (_, metrics), grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m      \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m   grads \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\n\u001b[1;32m    165\u001b[0m       \u001b[38;5;28;01mlambda\u001b[39;00m x, y: x\u001b[38;5;241m.\u001b[39mastype(y\u001b[38;5;241m.\u001b[39mdtype), grads, params\n\u001b[1;32m    166\u001b[0m   )\n\u001b[1;32m    167\u001b[0m   \u001b[38;5;66;03m# Helpful metric to print out during training.\u001b[39;00m\n",
            "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
            "Cell \u001b[0;32mIn[8], line 27\u001b[0m, in \u001b[0;36mloss_fn\u001b[0;34m(params, key, batch, bmnist_net, num_sweeps, num_particles)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Run the program and get metrics.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m program \u001b[38;5;241m=\u001b[39m make_bmnist(params, bmnist_net, batch_size, T, num_sweeps, num_particles)\n\u001b[0;32m---> 27\u001b[0m _, _, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcoix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraced_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng_key\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_Z\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_density\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     29\u001b[0m   metrics[metric_name] \u001b[38;5;241m=\u001b[39m metrics[metric_name] \u001b[38;5;241m/\u001b[39m batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/core.py:133\u001b[0m, in \u001b[0;36mtraced_evaluate.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 133\u001b[0m   out, trace, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out, desuffix(trace), metrics\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/numpyro.py:48\u001b[0m, in \u001b[0;36mtraced_evaluate.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m subs_model \u001b[38;5;241m=\u001b[39m handlers\u001b[38;5;241m.\u001b[39mseed(\n\u001b[1;32m     45\u001b[0m     handlers\u001b[38;5;241m.\u001b[39msubstitute(p, data\u001b[38;5;241m=\u001b[39mdata), rng_seed\u001b[38;5;241m=\u001b[39mrng_seed\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m handlers\u001b[38;5;241m.\u001b[39mblock(), handlers\u001b[38;5;241m.\u001b[39mtrace() \u001b[38;5;28;01mas\u001b[39;00m tr:\n\u001b[0;32m---> 48\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43msubs_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m trace \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, site \u001b[38;5;129;01min\u001b[39;00m tr\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/api.py:408\u001b[0m, in \u001b[0;36mfori_loop.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m   q \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mempirical(\u001b[38;5;241m*\u001b[39mval)\n\u001b[1;32m    406\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m trace_fn(body_fun(i, q), _fold_in_key(key_body, i))\n\u001b[0;32m--> 408\u001b[0m v, trace, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m metrics \u001b[38;5;241m=\u001b[39m _add_missing_metrics(metrics, trace)\n\u001b[1;32m    410\u001b[0m output \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mfori_loop(lower, upper, jax_body_fun, (v, trace, metrics))\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/api.py:393\u001b[0m, in \u001b[0;36mfori_loop.<locals>.fn.<locals>.trace_with_seed\u001b[0;34m(fn, key)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrace_with_seed\u001b[39m(fn, key):\n\u001b[0;32m--> 393\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraced_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/core.py:133\u001b[0m, in \u001b[0;36mtraced_evaluate.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 133\u001b[0m   out, trace, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out, desuffix(trace), metrics\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/numpyro.py:48\u001b[0m, in \u001b[0;36mtraced_evaluate.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m subs_model \u001b[38;5;241m=\u001b[39m handlers\u001b[38;5;241m.\u001b[39mseed(\n\u001b[1;32m     45\u001b[0m     handlers\u001b[38;5;241m.\u001b[39msubstitute(p, data\u001b[38;5;241m=\u001b[39mdata), rng_seed\u001b[38;5;241m=\u001b[39mrng_seed\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m handlers\u001b[38;5;241m.\u001b[39mblock(), handlers\u001b[38;5;241m.\u001b[39mtrace() \u001b[38;5;28;01mas\u001b[39;00m tr:\n\u001b[0;32m---> 48\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43msubs_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m trace \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, site \u001b[38;5;129;01min\u001b[39;00m tr\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/api.py:158\u001b[0m, in \u001b[0;36mpropose.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m q_latents \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    153\u001b[0m     name: util\u001b[38;5;241m.\u001b[39mget_site_value(site)\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, site \u001b[38;5;129;01min\u001b[39;00m q_trace\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m util\u001b[38;5;241m.\u001b[39mis_observed_site(site)\n\u001b[1;32m    156\u001b[0m }\n\u001b[1;32m    157\u001b[0m traced_p \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mtraced_evaluate(p, latents\u001b[38;5;241m=\u001b[39mq_latents)\n\u001b[0;32m--> 158\u001b[0m out, p_trace, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtraced_p\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mp_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m p_log_probs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    161\u001b[0m     name: util\u001b[38;5;241m.\u001b[39mget_site_log_prob(site) \u001b[38;5;28;01mfor\u001b[39;00m name, site \u001b[38;5;129;01min\u001b[39;00m p_trace\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    162\u001b[0m }\n\u001b[1;32m    163\u001b[0m q_log_probs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    164\u001b[0m     name: util\u001b[38;5;241m.\u001b[39mget_site_log_prob(site) \u001b[38;5;28;01mfor\u001b[39;00m name, site \u001b[38;5;129;01min\u001b[39;00m q_trace\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    165\u001b[0m }\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/core.py:133\u001b[0m, in \u001b[0;36mtraced_evaluate.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 133\u001b[0m   out, trace, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out, desuffix(trace), metrics\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/coix/numpyro.py:48\u001b[0m, in \u001b[0;36mtraced_evaluate.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m subs_model \u001b[38;5;241m=\u001b[39m handlers\u001b[38;5;241m.\u001b[39mseed(\n\u001b[1;32m     45\u001b[0m     handlers\u001b[38;5;241m.\u001b[39msubstitute(p, data\u001b[38;5;241m=\u001b[39mdata), rng_seed\u001b[38;5;241m=\u001b[39mrng_seed\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m handlers\u001b[38;5;241m.\u001b[39mblock(), handlers\u001b[38;5;241m.\u001b[39mtrace() \u001b[38;5;28;01mas\u001b[39;00m tr:\n\u001b[0;32m---> 48\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43msubs_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m trace \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, site \u001b[38;5;129;01min\u001b[39;00m tr\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/numpyro/primitives.py:105\u001b[0m, in \u001b[0;36mMessenger.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mbmnist_target\u001b[0;34m(network, inputs, batch_size, D, T)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbmnist_target\u001b[39m(network, inputs, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, D\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, T\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m   worms, x0s, y0s \u001b[38;5;241m=\u001b[39m \u001b[43msim_worms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   z_where \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;66;03m# worm_frames = []\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36msim_worms\u001b[0;34m(nworms, batch_size, n_frames)\u001b[0m\n\u001b[1;32m     29\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m: L, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m: A, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m: T, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkw\u001b[39m\u001b[38;5;124m'\u001b[39m: kw, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mku\u001b[39m\u001b[38;5;124m'\u001b[39m: ku, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minc\u001b[39m\u001b[38;5;124m'\u001b[39m: inc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdr\u001b[39m\u001b[38;5;124m'\u001b[39m: dr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase_1\u001b[39m\u001b[38;5;124m'\u001b[39m: phase_1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase_2\u001b[39m\u001b[38;5;124m'\u001b[39m: phase_2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase_3\u001b[39m\u001b[38;5;124m'\u001b[39m: phase_3, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: alpha, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx0\u001b[39m\u001b[38;5;124m'\u001b[39m: x0, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my0\u001b[39m\u001b[38;5;124m'\u001b[39m: y0}\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# L is a tensor. Assert that all values are within the range\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mall(L \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mall(L \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# kw\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mall(kw \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mall(kw \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m jnp\u001b[38;5;241m.\u001b[39mpi), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkw: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/jax/_src/core.py:1528\u001b[0m, in \u001b[0;36mconcretization_function_error.<locals>.error\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m-> 1528\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TracerBoolConversionError(arg)\n",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m: Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function step_fn at /home/frans/.local/lib/python3.12/site-packages/coix/util.py:160 for jit. This concrete value was not available in Python because it depends on the values of the arguments params['params']['encode_what']['Dense_0']['bias'], params['params']['encode_what']['Dense_0']['kernel'], params['params']['encode_what']['Dense_1']['bias'], params['params']['encode_what']['Dense_1']['kernel'], params['params']['encode_what']['Dense_2']['bias'], params['params']['encode_what']['Dense_2']['kernel'], params['params']['encode_what']['Dense_3']['bias'], params['params']['encode_what']['Dense_3']['kernel'], params['params']['encode_what']['LayerNorm_0']['bias'], params['params']['encode_what']['LayerNorm_0']['scale'], params['params']['encode_what']['LayerNorm_1']['bias'], params['params']['encode_what']['LayerNorm_1']['scale'], params['params']['encode_what']['ScanGRUCell_0']['hn']['bias'], params['params']['encode_what']['ScanGRUCell_0']['hn']['kernel'], params['params']['encode_what']['ScanGRUCell_0']['hr']['kernel'], params['params']['encode_what']['ScanGRUCell_0']['hz']['kernel'], params['params']['encode_what']['ScanGRUCell_0']['in']['bias'], params['params']['encode_what']['ScanGRUCell_0']['in']['kernel'], params['params']['encode_what']['ScanGRUCell_0']['ir']['bias'], params['params']['encode_what']['ScanGRUCell_0']['ir']['kernel'], params['params']['encode_what']['ScanGRUCell_0']['iz']['bias'], params['params']['encode_what']['ScanGRUCell_0']['iz']['kernel'], params['params']['encode_what']['carry_init'], params['params']['encode_where']['Dense_0']['bias'], params['params']['encode_where']['Dense_0']['kernel'], params['params']['encode_where']['Dense_1']['bias'], params['params']['encode_where']['Dense_1']['kernel'], params['params']['encode_where']['Dense_2']['bias'], params['params']['encode_where']['Dense_2']['kernel'], params['params']['encode_where']['Dense_3']['bias'], params['params']['encode_where']['Dense_3']['kernel'], args[0], and args[1].\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError"
          ]
        }
      ],
      "source": [
        "\n",
        "bmnist_params, _ = coix.util.train(\n",
        "    partial(\n",
        "        loss_fn,\n",
        "        bmnist_net=bmnist_net,\n",
        "        num_sweeps=num_sweeps,\n",
        "        num_particles=num_particles,\n",
        "    ),\n",
        "    init_params,\n",
        "    # optax.adam(lr),\n",
        "    opt,\n",
        "    num_steps,\n",
        "    train_ds,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 10, 64, 64)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load worm_learned_params.npy\n",
        "\n",
        "# bmnist_params = np.load(\"worm_learned_params.npy\", allow_pickle=True).item()\n",
        "\n",
        "np.save(\"worm_learned_params.npy\", bmnist_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "T_test = test_data.shape[-3]\n",
        "batch_size_test = test_data.shape[-4]\n",
        "program = make_bmnist(\n",
        "    bmnist_params, bmnist_net, batch_size_test, T_test, num_sweeps, num_particles\n",
        ")\n",
        "out, _, _ = coix.traced_evaluate(program, seed=jax.random.PRNGKey(1))(\n",
        "    test_data\n",
        ")\n",
        "out = out[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 5, 2, 2)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out[f\"z_where_{0}\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "b = 1\n",
        "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
        "colors = prop_cycle.by_key()[\"color\"]\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "def animate(i):\n",
        "  axes[0].cla()\n",
        "  axes[0].imshow(test_data[b, i])\n",
        "  axes[1].cla()\n",
        "  axes[1].imshow(out[\"frames_recon\"][0, b, i])\n",
        "  for d in range(2):\n",
        "    where = 0.5 * (out[f\"z_where_{i}\"][0, b, d] + 1) * (frame_size - 28) - 0.5\n",
        "    color = colors[d]\n",
        "    axes[0].add_patch(\n",
        "        Rectangle(where, 28, 28, edgecolor=color, lw=3, fill=False)\n",
        "    )\n",
        "plt.rc(\"animation\", html=\"jshtml\")\n",
        "plt.tight_layout()\n",
        "ani = animation.FuncAnimation(fig, animate, frames=range(10), interval=300)\n",
        "writer = animation.PillowWriter(fps=15)\n",
        "ani.save(\"bmnist.gif\", writer=writer)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser(description=\"Annealing example\")\n",
        "# parser.add_argument(\"--batch-size\", nargs=\"?\", default=5, type=int)\n",
        "# parser.add_argument(\"--num-sweeps\", nargs=\"?\", default=5, type=int)\n",
        "# parser.add_argument(\"--num_particles\", nargs=\"?\", default=10, type=int)\n",
        "# parser.add_argument(\"--learning-rate\", nargs=\"?\", default=1e-4, type=float)\n",
        "# parser.add_argument(\"--num-steps\", nargs=\"?\", default=20000, type=int)\n",
        "# parser.add_argument(\n",
        "#     \"--device\", default=\"gpu\", type=str, help='use \"cpu\" or \"gpu\".'\n",
        "# )\n",
        "# args = parser.parse_args()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.config.experimental.set_visible_devices([], \"GPU\")  # Disable GPU for TF.\n",
        "numpyro.set_platform(args.device)\n",
        "main(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = load_dataset(is_training=True, batch_size=args.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "foo = next(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
